<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x10. Natural Language Processing - Evaluation Metrics</h1><div id="project_id" style="display: none" data-project-id="689"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning ― Supervised Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 09-16-2020, must end by 09-19-2020 (in 1 day) - you're done with <span id="student_task_done_percentage">0</span>% of tasks. </small></p><p><small><i class="fa fa-check-square"></i> QA review fully automated. </small></p><article id="description" class="gap formatted-content"><h2>Resources</h2><p><strong>Read or watch:</strong></p><ul><li><a href="/rltoken/EFeppnrszrEGza6nrymxgQ" title="7 Applications of Deep Learning for Natural Language Processing" target="_blank">7 Applications of Deep Learning for Natural Language Processing</a></li><li><a href="/rltoken/Pcs54fB9zpZZWlMH_OamfQ" title="10 Applications of Artificial Neural Networks in Natural Language Processing" target="_blank">10 Applications of Artificial Neural Networks in Natural Language Processing</a></li><li><a href="/rltoken/lC85P6iX492bGuBncUNwiw" title="A Gentle Introduction to Calculating the BLEU Score for Text in Python" target="_blank">A Gentle Introduction to Calculating the BLEU Score for Text in Python</a></li><li><a href="/rltoken/lT-MBM6w7AjXPIiZoPKR_A" title="Bleu Score" target="_blank">Bleu Score</a></li><li><a href="/rltoken/en8Y6xcl0L2O2ETLSaX66A" title="Evaluating Text Output in NLP: BLEU at your own risk" target="_blank">Evaluating Text Output in NLP: BLEU at your own risk</a></li><li><a href="/rltoken/iaNCKPSMskZjUcw1hv8-pw" title="What Is ROUGE And How It Works For Evaluation Of Summarization Tasks?" target="_blank">What Is ROUGE And How It Works For Evaluation Of Summarization Tasks?</a></li><li><a href="/rltoken/8InyFuc-569qD7XbKchiHg" title="Evaluating Summaries ROUGE" target="_blank">Evaluating Summaries ROUGE</a></li><li><a href="/rltoken/Mgyoxa8c6WvpFJaHFxqlQQ" title="Evaluation and Perplexity" target="_blank">Evaluation and Perplexity</a></li><li><a href="/rltoken/rQ6MC0ZkpPjHBCEE3hpl4A" title="Predicting the Next Word: Back-Off Language Modeling" target="_blank">Predicting the Next Word: Back-Off Language Modeling</a></li></ul><p><strong>Definitions to skim</strong></p><ul><li><a href="/rltoken/njmmpbMuP0cPnnWwbFpj3A" title="BLEU" target="_blank">BLEU</a></li><li><a href="/rltoken/BJK2tEo1kVYXytMDoVF9fQ" title="ROUGE" target="_blank">ROUGE</a></li><li><a href="/rltoken/MayHONfLeczBB8qWvaDrkQ" title="Perplexity" target="_blank">Perplexity</a></li></ul><p><strong>References:</strong></p><ul><li><a href="/rltoken/F8q42L0L3uzw6RLlLj1QsQ" title="BLEU: a Method for Automatic Evaluation of Machine Translation (2002)" target="_blank">BLEU: a Method for Automatic Evaluation of Machine Translation (2002)</a></li><li><a href="/rltoken/gDkBzTZvzANW2xRpV5Ea5g" title="ROUGE: A Package for Automatic Evaluation of Summaries (2004)" target="_blank">ROUGE: A Package for Automatic Evaluation of Summaries (2004)</a></li></ul><h2>Learning Objectives</h2><p>At the end of this project, you are expected to be able to <a href="/rltoken/1x1paga16dECc8bSS9ddYQ" title="explain to anyone" target="_blank">explain to anyone</a>, <strong>without the help of Google</strong>:</p><h3>General</h3><ul><li>What are the applications of natural language processing?</li><li>What is a BLEU score?</li><li>What is a ROUGE score?</li><li>What is perplexity?</li><li>When should you use one evaluation metric over another?</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.15)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>All of your files must be executable</li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should follow the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li><li>You are not allowed to use the <code>nltk</code> module</li></ul></article><hr class="gap"><h2 class="gap">Quiz questions</h2><p id="quiz_questions_collapse_toggle">Show</p><section class="formatted-content quiz_questions_show_container" style="display: none;"><div class="quiz_question_item_container" data-role="quiz_question1171" data-position="1"><div class=" clearfix" id="quiz_question-1171"><h4 class="quiz_question">Question #0</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>The BLEU score measures:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1171"><li class=""><input type="checkbox" data-quiz-question-id="1171" data-quiz-answer-id="1594901354088" disabled=""><p>A model’s accuracy</p></li><li class=""><input type="checkbox" data-quiz-question-id="1171" data-quiz-answer-id="1594901355918" disabled="" checked=""><p>A model’s precision</p></li><li class=""><input type="checkbox" data-quiz-question-id="1171" data-quiz-answer-id="1594901357151" disabled=""><p>A model’s recall</p></li><li class=""><input type="checkbox" data-quiz-question-id="1171" data-quiz-answer-id="1594901358677" disabled=""><p>A model’s perplexity</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1172" data-position="2"><div class=" clearfix" id="quiz_question-1172"><h4 class="quiz_question">Question #1</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>The ROUGE score measures:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1172"><li class=""><input type="checkbox" data-quiz-question-id="1172" data-quiz-answer-id="1594901403019" disabled=""><p>A model’s accuracy</p></li><li class=""><input type="checkbox" data-quiz-question-id="1172" data-quiz-answer-id="1594901414214" disabled="" checked=""><p>A model’s precision</p></li><li class=""><input type="checkbox" data-quiz-question-id="1172" data-quiz-answer-id="1594901421842" disabled="" checked=""><p>A model’s recall</p></li><li class=""><input type="checkbox" data-quiz-question-id="1172" data-quiz-answer-id="1594901451064" disabled=""><p>A model’s perplexity</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1173" data-position="3"><div class=" clearfix" id="quiz_question-1173"><h4 class="quiz_question">Question #2</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>Perplexity measures:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1173"><li class=""><input type="checkbox" data-quiz-question-id="1173" data-quiz-answer-id="1594901553611" disabled=""><p>The accuracy of a prediction</p></li><li class=""><input type="checkbox" data-quiz-question-id="1173" data-quiz-answer-id="1594901572049" disabled="" checked=""><p>The branching factor of a prediction</p></li><li class=""><input type="checkbox" data-quiz-question-id="1173" data-quiz-answer-id="1594901683377" disabled=""><p>A prediction’s recall</p></li><li class=""><input type="checkbox" data-quiz-question-id="1173" data-quiz-answer-id="1594901689404" disabled=""><p>A prediction’s accuracy</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1174" data-position="4"><div class=" clearfix" id="quiz_question-1174"><h4 class="quiz_question">Question #3</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>The BLEU score was designed for:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1174"><li class=""><input type="checkbox" data-quiz-question-id="1174" data-quiz-answer-id="1594901820841" disabled=""><p>Sentiment Analysis</p></li><li class=""><input type="checkbox" data-quiz-question-id="1174" data-quiz-answer-id="1594901830774" disabled="" checked=""><p>Machine Translation</p></li><li class=""><input type="checkbox" data-quiz-question-id="1174" data-quiz-answer-id="1594901837617" disabled=""><p>Question-Answering</p></li><li class=""><input type="checkbox" data-quiz-question-id="1174" data-quiz-answer-id="1594901861763" disabled=""><p>Document Summarization</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1175" data-position="5"><div class=" clearfix" id="quiz_question-1175"><h4 class="quiz_question">Question #4</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What are the shortcomings of the BLEU score?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1175"><li class=""><input type="checkbox" data-quiz-question-id="1175" data-quiz-answer-id="1594901878460" disabled="" checked=""><p>It cannot judge grammatical accuracy</p></li><li class=""><input type="checkbox" data-quiz-question-id="1175" data-quiz-answer-id="1594901879890" disabled="" checked=""><p>It cannot judge meaning</p></li><li class=""><input type="checkbox" data-quiz-question-id="1175" data-quiz-answer-id="1594901881115" disabled="" checked=""><p>It does not work with languages that lack word boundaries</p></li><li class=""><input type="checkbox" data-quiz-question-id="1175" data-quiz-answer-id="1594901882506" disabled="" checked=""><p>A higher score is not necessarily indicative of a better translation</p></li></ul><!-- Quiz question Tips --></div></div></section><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task5417" data-position="1"><div class=" clearfix gap" id="task-5417"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5417"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5417" data-project-id="689" data-toggle="modal" data-target="#task-5417-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-5417-users-done-modal" data-task-id="5417" data-project-id="689"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "0. Unigram BLEU score"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 0. Unigram BLEU score <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def uni_bleu(references, sentence):</code> that calculates the unigram BLEU score for a sentence:</p><ul><li><code>references</code> is a list of reference translations <ul><li>each reference translation is a list of the words in the translation</li></ul></li><li><code>sentence</code> is a list containing the model proposed sentence</li><li>Returns: the unigram BLEU score</li></ul><precode language="" precodenum="0"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x10-nlp_metrics</code></li><li>File: <code>0-uni_bleu.py</code></li></ul></div></div><div data-role="task5418" data-position="2"><div class=" clearfix gap" id="task-5418"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5418"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5418" data-project-id="689" data-toggle="modal" data-target="#task-5418-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-5418-users-done-modal" data-task-id="5418" data-project-id="689"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "1. N-gram BLEU score"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 1. N-gram BLEU score <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def ngram_bleu(references, sentence, n):</code> that calculates the n-gram BLEU score for a sentence:</p><ul><li><code>references</code> is a list of reference translations <ul><li>each reference translation is a list of the words in the translation</li></ul></li><li><code>sentence</code> is a list containing the model proposed sentence</li><li><code>n</code> is the size of the n-gram to use for evaluation</li><li>Returns: the n-gram BLEU score</li></ul><precode language="" precodenum="1"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x10-nlp_metrics</code></li><li>File: <code>1-ngram_bleu.py</code></li></ul></div></div><div data-role="task5419" data-position="3"><div class=" clearfix gap" id="task-5419"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5419"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5419" data-project-id="689" data-toggle="modal" data-target="#task-5419-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-5419-users-done-modal" data-task-id="5419" data-project-id="689"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "2. Cumulative N-gram BLEU score"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 2. Cumulative N-gram BLEU score <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def cumulative_bleu(references, sentence, n):</code> that calculates the cumulative n-gram BLEU score for a sentence:</p><ul><li><code>references</code> is a list of reference translations <ul><li>each reference translation is a list of the words in the translation</li></ul></li><li><code>sentence</code> is a list containing the model proposed sentence</li><li><code>n</code> is the size of the largest n-gram to use for evaluation</li><li>All n-gram scores should be weighted evenly</li><li>Returns: the cumulative n-gram BLEU score</li></ul><precode language="" precodenum="2"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x10-nlp_metrics</code></li><li>File: <code>2-cumulative_bleu.py</code></li></ul></div></div></section></article>

