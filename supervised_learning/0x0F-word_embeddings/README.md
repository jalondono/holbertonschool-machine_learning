<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x0F. Natural Language Processing - Word Embeddings</h1><div id="project_id" style="display: none" data-project-id="604"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning ― Supervised Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 09-14-2020, must end by 09-16-2020 (in about 4 hours) - you're done with <span id="student_task_done_percentage">33</span>% of tasks. </small></p><p><small><i class="fa fa-check"></i> Checker was released at 09-15-2020 12:00 PM </small></p><p><small><i class="fa fa-check-square"></i><strong>Manual QA review must be done</strong> (request it when you are done with the project) </small></p><p><small><i class="fa fa-check-square"></i> QA review fully automated. </small></p><article id="description" class="gap formatted-content"><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/7/a2fa719214e8c81107842b9fcd97defd08ba3d82.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200916%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200916T004300Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=335d5ec6ca165519be30ec0f96c9a5a6e1126bbe306bb31cfb55087979f329a2" alt="" style=""></p><h2>Resources</h2><p><strong>Read or watch:</strong></p><ul><li><a href="/rltoken/-a-kPuLr3JNsmoBdj0Fnxg" title="An Introduction to Word Embeddings" target="_blank">An Introduction to Word Embeddings</a></li><li><a href="/rltoken/XcXiOu4G1cQmPsMCSV6iKg" title="Introduction to Word Embeddings" target="_blank">Introduction to Word Embeddings</a></li><li><a href="/rltoken/MFWRUck_pP6wWTo-Hk-uNA" title="Natural Language Processing|Bag Of Words Intuition" target="_blank">Natural Language Processing|Bag Of Words Intuition</a></li><li><a href="/rltoken/wNtfvYw0_t9__T34QullnQ" title="Natural Language Processing|TF-IDF Intuition| Text Prerocessing" target="_blank">Natural Language Processing|TF-IDF Intuition| Text Prerocessing</a></li><li><a href="/rltoken/EDAtqjDC2WJsCmc9DJHBsA" title="Word Embedding - Natural Language Processing| Deep Learning" target="_blank">Word Embedding - Natural Language Processing| Deep Learning</a></li><li><a href="/rltoken/e2onm8dzf3tnjAzhbqmY7w" title="Word2Vec Tutorial - The Skip-Gram Model" target="_blank">Word2Vec Tutorial - The Skip-Gram Model</a></li><li><a href="/rltoken/Oor3scClDEHAjTzs2UcLDg" title="Word2Vec Tutorial Part 2 - Negative Sampling" target="_blank">Word2Vec Tutorial Part 2 - Negative Sampling</a></li><li><a href="/rltoken/H8pvG3dA8erkvprE4w_cew" title="GloVe Explained" target="_blank">GloVe Explained</a></li><li><a href="/rltoken/maaJpd6ZpmRen6UitKcLoQ" title="FastText: Under the Hood" target="_blank">FastText: Under the Hood</a></li><li><a href="/rltoken/AgbAR_i53dGSLWFwcdJaBQ" title="ELMo Explained" target="_blank">ELMo Explained</a></li></ul><p><strong>Definitions to skim</strong></p><ul><li><a href="/rltoken/NLdhMq0eP7RCBdgTC2xXng" title="Natural Language Processing" target="_blank">Natural Language Processing</a></li></ul><p><strong>References:</strong></p><ul><li><a href="/rltoken/o6Kw0bZixZlCgSp8kv_d_A" title="Efficient Estimation of Word Representations in Vector Space (Skip-gram, 2013)" target="_blank">Efficient Estimation of Word Representations in Vector Space (Skip-gram, 2013)</a></li><li><a href="/rltoken/ibPaFuTAg_iFEUnXw6fi9g" title="Distributed Representations of Words and Phrases and their Compositionality (Word2Vec, 2013)" target="_blank">Distributed Representations of Words and Phrases and their Compositionality (Word2Vec, 2013)</a></li><li><a href="/rltoken/r_s4n4jWmHnUKnzd35_ayA" title="GloVe: Global Vectors for Word Representation (website)" target="_blank">GloVe: Global Vectors for Word Representation (website)</a></li><li><a href="/rltoken/m3mB2j5a1DLVtZs2yvjn9A" title="GloVe: Global Vectors for Word Representation (2014)" target="_blank">GloVe: Global Vectors for Word Representation (2014)</a></li><li><a href="/rltoken/XMu3K4vgAU3gXwdWbMYA7w" title="fastText (website)" target="_blank">fastText (website)</a></li><li><a href="/rltoken/gK1mwr5kB-fJL3aFab1lHQ" title="Bag of Tricks for Efficient Text Classification (fastText, 2016)" target="_blank">Bag of Tricks for Efficient Text Classification (fastText, 2016)</a></li><li><a href="/rltoken/QgTup8akJ4AXifvCTrNcYw" title="Enriching Word Vectors with Subword Information (fastText, 2017)" target="_blank">Enriching Word Vectors with Subword Information (fastText, 2017)</a></li><li><a href="/rltoken/0mqEv_KsCH8LRGIa1YpaiQ" title="Probabilistic FastText for Multi-Sense Word Embeddings (2018)" target="_blank">Probabilistic FastText for Multi-Sense Word Embeddings (2018)</a></li><li><a href="/rltoken/jAs-99Y2LO5u0ciCKLKOxw" title="ELMo (website)" target="_blank">ELMo (website)</a></li><li><a href="/rltoken/Waz8-ebrM2X8VNlmuVK3EQ" title="Deep contextualized word representations (ELMo, 2018)" target="_blank">Deep contextualized word representations (ELMo, 2018)</a></li><li><a href="/rltoken/KWBPHJxFppnvEBAdAqyoOQ" title="sklearn.feature_extraction.text.CountVectorizer" target="_blank">sklearn.feature_extraction.text.CountVectorizer</a></li><li><a href="/rltoken/L1tR8a5IxijX0iPSF9Zgdg" title="sklearn.feature_extraction.text.TfidfVectorizer" target="_blank">sklearn.feature_extraction.text.TfidfVectorizer</a></li><li><a href="/rltoken/-x-mXaagTBNvEUDbd1D84Q" title="genism.models.word2vec" target="_blank">genism.models.word2vec</a></li><li><a href="/rltoken/KvUoA9pXEKUOBaXb8Azd2g" title="genism.models.fasttext" target="_blank">genism.models.fasttext</a></li></ul><h2>Learning Objectives</h2><p>At the end of this project, you are expected to be able to <a href="/rltoken/tXju-4X_Z5aAxG7ROdFlvQ" title="explain to anyone" target="_blank">explain to anyone</a>, <strong>without the help of Google</strong>:</p><h3>General</h3><ul><li>What is natural language processing?</li><li>What is a word embedding?</li><li>What is bag of words?</li><li>What is TF-IDF?</li><li>What is CBOW?</li><li>What is a skip-gram?</li><li>What is an n-gram?</li><li>What is negative sampling?</li><li>What is word2vec, GloVe, fastText, ELMo?</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.15) and <code>tensorflow</code> (version 1.12)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>All of your files must be executable</li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should follow the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li></ul><h2>Download Gensim 3.8.x</h2><precode language="" precodenum="0"></precode><h2>Download Keras 2.2.5</h2><precode language="" precodenum="1"></precode></article><hr class="gap"><h2 class="gap">Quiz questions</h2><p id="quiz_questions_collapse_toggle">Show</p><section class="formatted-content quiz_questions_show_container" style="display: none;"><div class="quiz_question_item_container" data-role="quiz_question1163" data-position="1"><div class=" clearfix" id="quiz_question-1163"><h4 class="quiz_question">Question #0</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>Word2Vec uses:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1163"><li class=""><input type="checkbox" data-quiz-question-id="1163" data-quiz-answer-id="1594646265489" disabled=""><p>Character n-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1163" data-quiz-answer-id="1594646268580" disabled="" checked=""><p>Skip-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1163" data-quiz-answer-id="1594646270243" disabled="" checked=""><p>CBOW</p></li><li class=""><input type="checkbox" data-quiz-question-id="1163" data-quiz-answer-id="1594646271775" disabled=""><p>Co-occurrence matrices</p></li><li class=""><input type="checkbox" data-quiz-question-id="1163" data-quiz-answer-id="1594646805721" disabled="" checked=""><p>Negative sampling</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1164" data-position="2"><div class=" clearfix" id="quiz_question-1164"><h4 class="quiz_question">Question #1</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>GloVe uses:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1164"><li class=""><input type="checkbox" data-quiz-question-id="1164" data-quiz-answer-id="1594646358305" disabled=""><p>Character n-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1164" data-quiz-answer-id="1594646359608" disabled=""><p>Skip-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1164" data-quiz-answer-id="1594646361082" disabled=""><p>CBOW</p></li><li class=""><input type="checkbox" data-quiz-question-id="1164" data-quiz-answer-id="1594646362379" disabled="" checked=""><p>Co-occurrence matrices</p></li><li class=""><input type="checkbox" data-quiz-question-id="1164" data-quiz-answer-id="1594646818268" disabled=""><p>Negative sampling</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1165" data-position="3"><div class=" clearfix" id="quiz_question-1165"><h4 class="quiz_question">Question #2</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>FastText uses:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1165"><li class=""><input type="checkbox" data-quiz-question-id="1165" data-quiz-answer-id="1594646568330" disabled="" checked=""><p>Character n-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1165" data-quiz-answer-id="1594646569609" disabled="" checked=""><p>Skip-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1165" data-quiz-answer-id="1594646570945" disabled="" checked=""><p>CBOW</p></li><li class=""><input type="checkbox" data-quiz-question-id="1165" data-quiz-answer-id="1594646572354" disabled=""><p>Co-occurrence matrices</p></li><li class=""><input type="checkbox" data-quiz-question-id="1165" data-quiz-answer-id="1594646830647" disabled="" checked=""><p>Negative sampling</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1166" data-position="4"><div class=" clearfix" id="quiz_question-1166"><h4 class="quiz_question">Question #3</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>ELMo uses:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1166"><li class=""><input type="checkbox" data-quiz-question-id="1166" data-quiz-answer-id="1594646676768" disabled="" checked=""><p>Character n-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1166" data-quiz-answer-id="1594646677803" disabled=""><p>Skip-grams</p></li><li class=""><input type="checkbox" data-quiz-question-id="1166" data-quiz-answer-id="1594646678960" disabled=""><p>CBOW</p></li><li class=""><input type="checkbox" data-quiz-question-id="1166" data-quiz-answer-id="1594646680483" disabled=""><p>Co-occurrence matrices</p></li><li class=""><input type="checkbox" data-quiz-question-id="1166" data-quiz-answer-id="1594646792783" disabled=""><p>Negative sampling</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1167" data-position="5"><div class=" clearfix" id="quiz_question-1167"><h4 class="quiz_question">Question #4</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>Which of the following can be used in conjunction with the others?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1167"><li class=""><input type="checkbox" data-quiz-question-id="1167" data-quiz-answer-id="1594646642897" disabled=""><p>Word2Vec</p></li><li class=""><input type="checkbox" data-quiz-question-id="1167" data-quiz-answer-id="1594646644225" disabled=""><p>GloVe</p></li><li class=""><input type="checkbox" data-quiz-question-id="1167" data-quiz-answer-id="1594646645520" disabled=""><p>FastText</p></li><li class=""><input type="checkbox" data-quiz-question-id="1167" data-quiz-answer-id="1594646646922" disabled="" checked=""><p>ELMo</p></li></ul><!-- Quiz question Tips --></div></div></section><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task5397" data-position="1"><div class=" clearfix gap" id="task-5397"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5397"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5397" data-project-id="604" data-toggle="modal" data-target="#task-5397-users-done-modal"> Help </button></div><h4 class="task"> 0. Bag Of Words <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def bag_of_words(sentences, vocab=None):</code> that creates a bag of words embedding matrix:</p><ul><li><code>sentences</code> is a list of sentences to analyze</li><li><code>vocab</code> is a list of the vocabulary words to use for the analysis <ul><li>If <code>None</code>, all words within <code>sentences</code> should be used</li></ul></li><li>Returns: <code>embeddings, features</code><ul><li><code>embeddings</code> is a <code>numpy.ndarray</code> of shape <code>(s, f)</code> containing the embeddings <ul><li><code>s</code> is the number of sentences in <code>sentences</code></li><li><code>f</code> is the number of features analyzed</li></ul></li><li><code>features</code> is a list of the features used for <code>embeddings</code></li></ul></li></ul><precode language="" precodenum="2"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>0-bag_of_words.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5397" data-toggle="modal" data-target="#task-5397-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5397-whiteboard-modal" data-task-id="5397">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "0. Bag Of Words"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5397" data-toggle="modal" data-target="#task-test-correction-5397-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5398" data-position="2"><div class=" clearfix gap" id="task-5398"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default yes" data-task-id="5398"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5398" data-project-id="604" data-toggle="modal" data-target="#task-5398-users-done-modal"> Help </button></div><h4 class="task"> 1. TF-IDF <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def tf_idf(sentences, vocab=None):</code> that creates a TF-IDF embedding:</p><ul><li><code>sentences</code> is a list of sentences to analyze</li><li><code>vocab</code> is a list of the vocabulary words to use for the analysis <ul><li>If <code>None</code>, all words within <code>sentences</code> should be used</li></ul></li><li>Returns: <code>embeddings, features</code><ul><li><code>embeddings</code> is a <code>numpy.ndarray</code> of shape <code>(s, f)</code> containing the embeddings <ul><li><code>s</code> is the number of sentences in <code>sentences</code></li><li><code>f</code> is the number of features analyzed</li></ul></li><li><code>features</code> is a list of the features used for <code>embeddings</code></li></ul></li></ul><precode language="" precodenum="3"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>1-tf_idf.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5398" data-toggle="modal" data-target="#task-5398-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5398-whiteboard-modal" data-task-id="5398">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "1. TF-IDF"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5398" data-toggle="modal" data-target="#task-test-correction-5398-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5399" data-position="3"><div class=" clearfix gap" id="task-5399"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5399"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5399" data-project-id="604" data-toggle="modal" data-target="#task-5399-users-done-modal"> Help </button></div><h4 class="task"> 2. Train Word2Vec <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def word2vec_model(sentences, size=100, min_count=5, window=5, negative=5, cbow=True, iterations=5, seed=0, workers=1):</code> that creates and trains a <code>gensim</code>¨NBSP;<code>word2vec</code> model:</p><ul><li><code>sentences</code> is a list of sentences to be trained on</li><li><code>size</code> is the dimensionality of the embedding layer</li><li><code>min_count</code> is the minimum number of occurrences of a word for use in training</li><li><code>window</code> is the maximum distance between the current and predicted word within a sentence</li><li><code>negative</code> is the size of negative sampling</li><li><code>cbow</code> is a boolean to determine the training type; <code>True</code> is for CBOW; <code>False</code> is for Skip-gram</li><li><code>iterations</code> is the number of iterations to train over</li><li><code>seed</code> is the seed for the random number generator</li><li><code>workers</code> is the number of worker threads to train the model</li><li>Returns: the trained model</li></ul><precode language="" precodenum="4"></precode><p><em>Note: gensim is not inherently deterministic and therefore your outputs may vary</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>2-word2vec.py</code></li></ul></div></div><div data-role="task5400" data-position="4"><div class=" clearfix gap" id="task-5400"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5400"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5400" data-project-id="604" data-toggle="modal" data-target="#task-5400-users-done-modal"> Help </button></div><h4 class="task"> 3. Extract Word2Vec <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def gensim_to_keras(model):</code> that converts a <code>gensim</code><code>word2vec</code> model to a <code>keras</code> Embedding layer:</p><ul><li><code>model</code> is a trained <code>gensim</code><code>word2vec</code> models</li><li>Returns: the trainable <code>keras</code> Embedding</li></ul><precode language="" precodenum="5"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>3-gensim_to_keras.py</code></li></ul></div></div><div data-role="task5401" data-position="5"><div class=" clearfix gap" id="task-5401"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5401"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5401" data-project-id="604" data-toggle="modal" data-target="#task-5401-users-done-modal"> Help </button></div><h4 class="task"> 4. FastText <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def fasttext_model(sentences, size=100, min_count=5, negative=5, window=5, cbow=True, iterations=5, seed=0, workers=1):</code> that creates and trains a <code>genism</code><code>fastText</code> model:</p><ul><li><code>sentences</code> is a list of sentences to be trained on</li><li><code>size</code> is the dimensionality of the embedding layer</li><li><code>min_count</code> is the minimum number of occurrences of a word for use in training</li><li><code>window</code> is the maximum distance between the current and predicted word within a sentence</li><li><code>negative</code> is the size of negative sampling</li><li><code>cbow</code> is a boolean to determine the training type; <code>True</code> is for CBOW; <code>False</code> is for Skip-gram</li><li><code>iterations</code> is the number of iterations to train over</li><li><code>seed</code> is the seed for the random number generator</li><li><code>workers</code> is the number of worker threads to train the model</li><li>Returns: the trained model</li></ul><precode language="" precodenum="6"></precode><p><em>Note: gensim is not inherently deterministic and therefore your outputs may vary</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>4-fasttext.py</code></li></ul></div></div><div data-role="task5402" data-position="6"><div class=" clearfix gap" id="task-5402"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default yes" data-task-id="5402"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5402" data-project-id="604" data-toggle="modal" data-target="#task-5402-users-done-modal"> Help </button></div><h4 class="task"> 5. ELMo <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>When training an ELMo embedding model, you are training:</p><ol><li>The internal weights of the BiLSTM</li><li>The character embedding layer</li><li>The weights applied to the hidden states</li></ol><p>In the text file <code>5-elmo</code>, write the letter answer, followed by a newline, that lists the correct statements:</p><ul><li>A. 1, 2, 3</li><li>B. 1, 2</li><li>C. 2, 3</li><li>D. 1, 3</li><li>E. 1</li><li>F. 2</li><li>G. 3</li><li>H. None of the above</li></ul><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x0F-word_embeddings</code></li><li>File: <code>5-elmo</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5402" data-toggle="modal" data-target="#task-5402-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5402-whiteboard-modal" data-task-id="5402">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "5. ELMo"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5402" data-toggle="modal" data-target="#task-test-correction-5402-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div></section></article>
