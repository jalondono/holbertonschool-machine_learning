<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x11. Attention</h1><div id="project_id" style="display: none" data-project-id="570"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning ― Supervised Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 09-21-2020, must end by 09-26-2020 (in 1 day) - you're done with <span id="student_task_done_percentage">0</span>% of tasks. </small></p><p><small><i class="fa fa-check"></i> Checker was released at 09-24-2020 12:00 AM </small></p><p><small><i class="fa fa-check-square"></i> QA review fully automated. </small></p><article id="description" class="gap formatted-content"><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/7/4704cf0750335400050c494f69844150e6319d1b.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200924%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200924T183051Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=d92d5b423314451ce95ec428594c356a6c29ff18ad09c5bc91cf61190f26db2c" alt="" style=""></p><h2>Resources:</h2><p><strong>Read or watch:</strong></p><ul><li><a href="/rltoken/KKW6LXmtOfzDrQCtX3trpg" title="How Does Attention Work in Encoder-Decoder Recurrent Neural Networks" target="_blank">How Does Attention Work in Encoder-Decoder Recurrent Neural Networks</a></li><li><a href="/rltoken/pw8xV6DMI1yMKY05Rzhq0g" title="Attention Model" target="_blank">Attention Model</a></li><li><a href="/rltoken/ju6UjnXhDuMFS6LzEIlj0Q" title="What is a Transformer?" target="_blank">What is a Transformer?</a></li><li><a href="/rltoken/uQo7gV_pYZi9ZGLNG0dasA" title="How Transformers Work" target="_blank">How Transformers Work</a></li><li><a href="/rltoken/zeZrN58D0iOt161zLNqUMw" title="Transformer: A Novel Neural Network Architecture for Language Understanding" target="_blank">Transformer: A Novel Neural Network Architecture for Language Understanding</a></li><li><a href="/rltoken/01S-rlsZr6WfdsqMC2BEYQ" title="Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 – Transformers and Self-Attention" target="_blank">Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 – Transformers and Self-Attention</a></li><li><a href="/rltoken/AEZqvJXaWBEZVdGKy57yQw" title="(Transformer) Attention Is All You Need | AISC Foundational" target="_blank">(Transformer) Attention Is All You Need | AISC Foundational</a></li><li><a href="/rltoken/vdCwNWQ6pM10Rc2g2Nwo0A" title="Transformer Models in NLP" target="_blank">Transformer Models in NLP</a></li><li><a href="/rltoken/4o_KAqoKcamqDfuQ6OmI6g" title="Transformer model for language understanding" target="_blank">Transformer model for language understanding</a></li><li><a href="/rltoken/ukLu5CMMIoP_4Yt7MNY8UQ" title="Generative Modeling with Sparse Transformers" target="_blank">Generative Modeling with Sparse Transformers</a></li><li><a href="/rltoken/cXTOtTK9waaB-tM5C3EAMQ" title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li><li><a href="/rltoken/FoCSA7ZVrzZyTGUGIgEtPg" title="(BERT) Pretranied Deep Bidirectional Transformers for Language Understanding (algorithm) | TDLS" target="_blank">(BERT) Pretranied Deep Bidirectional Transformers for Language Understanding (algorithm) | TDLS</a></li></ul><p><strong>References:</strong></p><ul><li><a href="/rltoken/v3oiayVt7mUWFVHp-LsSlw" title="Sequence to Sequence Learning with Neural Networks (2014)" target="_blank">Sequence to Sequence Learning with Neural Networks (2014)</a></li><li><a href="/rltoken/cSywNMc0VkeDq4TZ4V8nEg" title="Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (2014)" target="_blank">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (2014)</a></li><li><a href="/rltoken/YlDIODUFbkYQbRL3a5CwEQ" title="Neural Machine Translation by Jointly Learning to Align and Translate" target="_blank">Neural Machine Translation by Jointly Learning to Align and Translate</a></li><li><a href="/rltoken/V29PxakOS66KNWeS016NAQ" title="Attention Is All You Need (2017)" target="_blank">Attention Is All You Need (2017)</a></li><li><a href="/rltoken/XEpXcqIg5l9DoS2-2E7InQ" title="tf.keras.layers.Embedding" target="_blank">tf.keras.layers.Embedding</a></li><li><a href="/rltoken/-qb21N0gxX5UmRub_bLasg" title="tf.keras.layers.LayerNormalization" target="_blank">tf.keras.layers.LayerNormalization</a></li><li><a href="/rltoken/fBJbaYK3mQliTYVmerk8Gw" title="Improving Language Understanding by Generative Pre-Training (2018)" target="_blank">Improving Language Understanding by Generative Pre-Training (2018)</a></li><li><a href="/rltoken/Xo7RMyK_8WiLXaerfTHoWw" title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2018)" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2018)</a></li><li><a href="/rltoken/hj1iAmCUDCnH72SGnTxsXA" title="SQuAD 2.0" target="_blank">SQuAD 2.0</a></li><li><a href="/rltoken/2gCjBpi3CDZ25VyRnwy3ow" title="Know What You Don’t Know: Unanswerable Questions for SQuAD (2018)" target="_blank">Know What You Don’t Know: Unanswerable Questions for SQuAD (2018)</a></li><li><a href="/rltoken/XQMKBVpVRJ7PH_Fam-mYkw" title="GLUE Benchmark" target="_blank">GLUE Benchmark</a></li><li><a href="/rltoken/gc0N-1a5GhwB6r8i4-PJ4A" title="GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (2019)" target="_blank">GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (2019)</a></li></ul><p><strong>More recent papers in NLP:</strong></p><ul><li><a href="/rltoken/Vr6j7CGFKtuK7IetaIeMcw" title="Generating Long Sequences with Sparse Transformers (2019)" target="_blank">Generating Long Sequences with Sparse Transformers (2019)</a></li><li><a href="/rltoken/kEkphkks_kGLj3XuXBMCAA" title="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context (2019)" target="_blank">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context (2019)</a></li><li><a href="/rltoken/THgst72PaoA0cYrpfOQWDA" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding (2019)" target="_blank">XLNet: Generalized Autoregressive Pretraining for Language Understanding (2019)</a></li><li><a href="/rltoken/C2rjrR_0Dq0_XU8Bu9INbQ" title="Language Models are Unsupervised Multitask Learners (GPT-2, 2019)" target="_blank">Language Models are Unsupervised Multitask Learners (GPT-2, 2019)</a></li><li><a href="/rltoken/2y-mtFWYnQ8QbtMij0PoWA" title="Language Models are Few-Shot Learners (GPT-3, 2020)" target="_blank">Language Models are Few-Shot Learners (GPT-3, 2020)</a></li><li><a href="/rltoken/u6oVFipCalDn-X1QTwVsPA" title="ALBERT: A Lite BERT for Self-Supervised Learning of Language Representations (2020)" target="_blank">ALBERT: A Lite BERT for Self-Supervised Learning of Language Representations (2020)</a></li></ul><p>To keep up with the newest papers and their code bases go to <a href="/rltoken/3VaoLjK3QGn7jJbnU6MpKQ" title="paperswithcode.com" target="_blank">paperswithcode.com</a>. For example, check out the <a href="/rltoken/v3qkGtmWqnn_M3JgkqukYQ" title="raked list of state of the art models for Language Modelling on Penn Treebank" target="_blank">raked list of state of the art models for Language Modelling on Penn Treebank</a>.</p><h2>Learning Objectives</h2><p>At the end of this project, you are expected to be able to <a href="/rltoken/rm_YJ9QKGU1TCkyffIRbDg" title="explain to anyone" target="_blank">explain to anyone</a>, <strong>without the help of Google</strong>:</p><h3>General</h3><ul><li>What is the attention mechanism?</li><li>How to apply attention to RNNs</li><li>What is a transformer?</li><li>How to create an encoder-decoder transformer model</li><li>What is GPT? </li><li>What is BERT?</li><li>What is self-supervised learning?</li><li>How to use BERT for specific NLP tasks</li><li>What is SQuAD? GLUE?</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.16) and <code>tensorflow</code> (version 1.15)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>All of your files must be executable</li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should follow the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li><li>Unless otherwise stated, you cannot import any module except <code>import tensorflow as tf</code></li></ul><h2>Update Tensorflow to 1.15</h2><p>In order to complete the following tasks, you will need to update <code>tensorflow</code> to version 1.15, which will also update <code>numpy</code> to version 1.16</p><precode language="" precodenum="0"></precode></article><hr class="gap"><h2 class="gap">Quiz questions</h2><p id="quiz_questions_collapse_toggle">Show</p><section class="formatted-content quiz_questions_show_container" style="display: none;"><div class="quiz_question_item_container" data-role="quiz_question1176" data-position="1"><div class=" clearfix" id="quiz_question-1176"><h4 class="quiz_question">Question #0</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is the Attention mechanism?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1176"><li class=""><input type="checkbox" data-quiz-question-id="1176" data-quiz-answer-id="1595234544860" disabled=""><p>An RNN</p></li><li class=""><input type="checkbox" data-quiz-question-id="1176" data-quiz-answer-id="1595234549308" disabled=""><p>A transformer</p></li><li class=""><input type="checkbox" data-quiz-question-id="1176" data-quiz-answer-id="1595234554668" disabled="" checked=""><p>A method for determining which terms are most important in a sequence</p></li><li class=""><input type="checkbox" data-quiz-question-id="1176" data-quiz-answer-id="1595234584997" disabled=""><p>None of the above</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1177" data-position="2"><div class=" clearfix" id="quiz_question-1177"><h4 class="quiz_question">Question #1</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>A Transformer:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1177"><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234660592" disabled="" checked=""><p>Is a novel neural network</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234670724" disabled="" checked=""><p>Utilizes the Attention mechanism</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234755112" disabled=""><p>Utilizes RNNs</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234799367" disabled="" checked=""><p>Utilizes Fully Connected Networks</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234811317" disabled=""><p>Utilizes CNNs</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595234818774" disabled="" checked=""><p>Utilizes dropout</p></li><li class=""><input type="checkbox" data-quiz-question-id="1177" data-quiz-answer-id="1595235280601" disabled="" checked=""><p>Utilizes layer normalization</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1178" data-position="3"><div class=" clearfix" id="quiz_question-1178"><h4 class="quiz_question">Question #2</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>BERT was novel because:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1178"><li class=""><input type="checkbox" data-quiz-question-id="1178" data-quiz-answer-id="1595234847158" disabled=""><p>It used transformers for the first time</p></li><li class=""><input type="checkbox" data-quiz-question-id="1178" data-quiz-answer-id="1595234857866" disabled="" checked=""><p>It introduced self-supervised learning techniques</p></li><li class=""><input type="checkbox" data-quiz-question-id="1178" data-quiz-answer-id="1595234898073" disabled=""><p>It utilized layer normalization for the first time</p></li><li class=""><input type="checkbox" data-quiz-question-id="1178" data-quiz-answer-id="1595234917083" disabled="" checked=""><p>It can be fine tuned for various NLP tasks</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1179" data-position="4"><div class=" clearfix" id="quiz_question-1179"><h4 class="quiz_question">Question #3</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>The database to use for Question-Answering is:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1179"><li class=""><input type="checkbox" data-quiz-question-id="1179" data-quiz-answer-id="1595234942150" disabled=""><p>GLUE</p></li><li class=""><input type="checkbox" data-quiz-question-id="1179" data-quiz-answer-id="1595234947163" disabled="" checked=""><p>SQuAD</p></li><li class=""><input type="checkbox" data-quiz-question-id="1179" data-quiz-answer-id="1595234951733" disabled=""><p>Penn Treebank</p></li><li class=""><input type="checkbox" data-quiz-question-id="1179" data-quiz-answer-id="1595235014697" disabled=""><p>WikiText</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1180" data-position="5"><div class=" clearfix" id="quiz_question-1180"><h4 class="quiz_question">Question #4</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>Layer Normalization is different from Batch Normalization because:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1180"><li class=""><input type="checkbox" data-quiz-question-id="1180" data-quiz-answer-id="1595235037335" disabled="" checked=""><p>It normalizes the layer output for each example instead of across the batch</p></li><li class=""><input type="checkbox" data-quiz-question-id="1180" data-quiz-answer-id="1595235103776" disabled=""><p>It normalizes the layer output across the batch instead of for each example</p></li><li class=""><input type="checkbox" data-quiz-question-id="1180" data-quiz-answer-id="1595235160111" disabled=""><p>It learns the gamma and beta constants</p></li><li class=""><input type="checkbox" data-quiz-question-id="1180" data-quiz-answer-id="1595235183247" disabled=""><p>It does not need to learn the gamma and beta constants</p></li></ul><!-- Quiz question Tips --></div></div></section><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task5420" data-position="1"><div class=" clearfix gap" id="task-5420"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5420"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5420" data-project-id="570" data-toggle="modal" data-target="#task-5420-users-done-modal"> Help </button></div><h4 class="task"> 0. RNN Encoder <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>RNNEncoder</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to encode for machine translation:</p><ul><li>Class constructor <code>def __init__(self, vocab, embedding, units, batch):</code><ul><li><code>vocab</code> is an integer representing the size of the input vocabulary</li><li><code>embedding</code> is an integer representing the dimensionality of the embedding vector</li><li><code>units</code> is an integer representing the number of hidden units in the RNN cell</li><li><code>batch</code> is an integer representing the batch size</li><li>Sets the following public instance attributes: <ul><li><code>batch</code> - the batch size</li><li><code>units</code> - the number of hidden units in the RNN cell</li><li><code>embedding</code> - a <code>keras</code> Embedding layer that converts words from the vocabulary into an embedding vector</li><li><code>gru</code> - a <code>keras</code> GRU layer with <code>units</code> units <ul><li>Should return both the full sequence of outputs as well as the last hidden state</li><li>Recurrent weights should be initialized with <code>glorot_uniform</code></li></ul></li></ul></li></ul></li><li>Public instance method <code>def initialize_hidden_state(self):</code><ul><li>Initializes the hidden states for the RNN cell to a tensor of zeros</li><li>Returns: a tensor of shape <code>(batch, units)</code>containing the initialized hidden states</li></ul></li><li> Public instance method <code>def call(self, x, initial):</code><ul><li>¨NBSP;<code>x</code> is a tensor of shape <code>(batch, input_seq_len)</code> containing the input to the encoder layer as word indices within the vocabulary</li><li><code>initial</code> is a tensor of shape <code>(batch, units)</code> containing the initial hidden state</li><li> Returns: <code>outputs, hidden</code><ul><li><code>outputs</code> is a tensor of shape <code>(batch, input_seq_len, units)</code>containing the outputs of the encoder</li><li><code>hidden</code> is a tensor of shape <code>(batch, units)</code> containing the last hidden state of the encoder</li></ul></li></ul></li></ul><precode language="" precodenum="1"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>0-rnn_encoder.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5420" data-toggle="modal" data-target="#task-5420-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5420-whiteboard-modal" data-task-id="5420">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "0. RNN Encoder"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5420" data-toggle="modal" data-target="#task-test-correction-5420-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5421" data-position="2"><div class=" clearfix gap" id="task-5421"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5421"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5421" data-project-id="570" data-toggle="modal" data-target="#task-5421-users-done-modal"> Help </button></div><h4 class="task"> 1. Self Attention <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>SelfAttention</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to calculate the attention for machine translation based on <a href="/rltoken/YlDIODUFbkYQbRL3a5CwEQ" title="this paper" target="_blank">this paper</a>:</p><ul><li>Class constructor <code>def __init__(self, units):</code><ul><li><code>units</code> is an integer representing the number of hidden units in the alignment model</li><li> Sets the following public instance attributes: <ul><li><code>W</code> - a Dense layer with <code>units</code> units, to be applied to the previous decoder hidden state</li><li><code>U</code> - a Dense layer with <code>units</code> units, to be applied to the encoder hidden states</li><li><code>V</code> - a Dense layer with <code>1</code> units, to be applied to the tanh of the sum of the outputs of <code>W</code> and <code>U</code></li></ul></li></ul></li><li>Public instance method <code>def call(self, s_prev, hidden_states):</code><ul><li><code>s_prev</code> is a tensor of shape <code>(batch, units)</code> containing the previous decoder hidden state</li><li><code>hidden_states</code> is a tensor of shape <code>(batch, input_seq_len, units)</code>containing the outputs of the encoder</li><li>Returns: <code>context, weights</code><ul><li><code>context</code> is a tensor of shape <code>(batch, units)</code> that contains the context vector for the decoder</li><li><code>weights</code> is a tensor of shape <code>(batch, input_seq_len, 1)</code> that contains the attention weights</li></ul></li></ul></li></ul><precode language="" precodenum="2"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>1-self_attention.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5421" data-toggle="modal" data-target="#task-5421-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5421-whiteboard-modal" data-task-id="5421">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "1. Self Attention"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5421" data-toggle="modal" data-target="#task-test-correction-5421-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5422" data-position="3"><div class=" clearfix gap" id="task-5422"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5422"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5422" data-project-id="570" data-toggle="modal" data-target="#task-5422-users-done-modal"> Help </button></div><h4 class="task"> 2. RNN Decoder <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>RNNDecoder</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to decode for machine translation:</p><ul><li>Class constructor <code>def __init__(self, vocab, embedding, units, batch):</code><ul><li><code>vocab</code> is an integer representing the size of the output vocabulary</li><li><code>embedding</code> is an integer representing the dimensionality of the embedding vector</li><li><code>units</code> is an integer representing the number of hidden units in the RNN cell</li><li><code>batch</code> is an integer representing the batch size</li><li>Sets the following public instance attributes: <ul><li><code>embedding</code> - a <code>keras</code> Embedding layer that converts words from the vocabulary into an embedding vector</li><li><code>gru</code> - a <code>keras</code> GRU layer with <code>units</code> units <ul><li>Should return both the full sequence of outputs as well as the last hidden state</li><li>Recurrent weights should be initialized with <code>glorot_uniform</code></li></ul></li><li><code>F</code> - a Dense layer with <code>vocab</code> units</li></ul></li></ul></li><li>Public instance method <code>def call(self, x, s_prev, hidden_states):</code><ul><li><code>x</code> is a tensor of shape <code>(batch, 1)</code> containing the previous word in the target sequence as an index of the target vocabulary</li><li><code>s_prev</code> is a tensor of shape <code>(batch, units)</code> containing the previous decoder hidden state</li><li><code>hidden_states</code> is a tensor of shape <code>(batch, input_seq_len, units)</code>containing the outputs of the encoder</li><li>You can use <code>SelfAttention = __import__('1-self_attention').SelfAttention</code></li><li>You should concatenate the context vector with x in that order</li><li>Returns: <code>y, s</code><ul><li><code>y</code> is a tensor of shape <code>(batch, vocab)</code> containing the output word as a one hot vector in the target vocabulary</li><li><code>s</code> is a tensor of shape <code>(batch, units)</code> containing the new decoder hidden state</li></ul></li></ul></li></ul><precode language="" precodenum="3"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>2-rnn_decoder.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5422" data-toggle="modal" data-target="#task-5422-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5422-whiteboard-modal" data-task-id="5422">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "2. RNN Decoder"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5422" data-toggle="modal" data-target="#task-test-correction-5422-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5424" data-position="5"><div class=" clearfix gap" id="task-5424"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5424"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5424" data-project-id="570" data-toggle="modal" data-target="#task-5424-users-done-modal"> Help </button></div><h4 class="task"> 3. Positional Encoding <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def positional_encoding(max_seq_len, dm):</code> that calculates the positional encoding for a transformer:</p><ul><li><code>max_seq_len</code> is an integer representing the maximum sequence length</li><li><code>dm</code> is the model depth</li><li>Returns: a <code>numpy.ndarray</code> of shape <code>(max_seq_len, dm)</code> containing the positional encoding vectors</li><li>You can use <code>import numpy as np</code></li></ul><precode language="" precodenum="4"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>4-positional_encoding.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5424" data-toggle="modal" data-target="#task-5424-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5424-whiteboard-modal" data-task-id="5424">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "3. Positional Encoding"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5424" data-toggle="modal" data-target="#task-test-correction-5424-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5425" data-position="6"><div class=" clearfix gap" id="task-5425"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5425"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5425" data-project-id="570" data-toggle="modal" data-target="#task-5425-users-done-modal"> Help </button></div><h4 class="task"> 4. Scaled Dot Product Attention <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/7/8f5aadef511d9f646f5009756035b472073fe896.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200924%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200924T183051Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=6ce2a6757181f968a2f66d625fd7ffd215c10f3f40e8334e74bad55f484a7928" alt="" style=""></p><p>Write the function <code>def sdp_attention(Q, K, V, mask=None)</code> that calculates the scaled dot product attention:</p><ul><li><code>Q</code> is a tensor with its last two dimensions as <code>(..., seq_len_q, dk)</code> containing the query matrix</li><li><code>K</code> is a tensor with its last two dimensions as <code>(..., seq_len_v, dk)</code> containing the key matrix</li><li><code>V</code> is a tensor with its last two dimensions as <code>(..., seq_len_v, dv)</code> containing the value matrix</li><li><code>mask</code> is a tensor that can be broadcast into <code>(..., seq_len_q, seq_len_v)</code> containing the optional mask, or defaulted to <code>None</code><ul><li>if <code>mask</code> is not <code>None</code>, multiply <code>-1e9</code> to the mask and add it to the scaled matrix multiplication </li></ul></li><li>The preceding dimensions of <code>Q</code>, <code>K</code>, and <code>V</code> are the same</li><li>Returns: <code>output, weights</code><ul><li><code>output</code>a tensor with its last two dimensions as <code>(..., seq_len_q, dv)</code> containing the scaled dot product attention</li><li><code>weights</code> a tensor with its last two dimensions as <code>(..., seq_len_q, seq_len_v)</code> containing the attention weights</li></ul></li></ul><precode language="" precodenum="5"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>5-sdp_attention.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5425" data-toggle="modal" data-target="#task-5425-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5425-whiteboard-modal" data-task-id="5425">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "4. Scaled Dot Product Attention"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5425" data-toggle="modal" data-target="#task-test-correction-5425-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5426" data-position="7"><div class=" clearfix gap" id="task-5426"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5426"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5426" data-project-id="570" data-toggle="modal" data-target="#task-5426-users-done-modal"> Help </button></div><h4 class="task"> 5. Multi Head Attention <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/7/4a5aaa54ebdc32529b4f09a5f22789dc267e0796.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200924%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200924T183051Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=312f0ed71181d7f1e670ba5734ad0a47a5635cd80c96e8a241275c62f4a42ed4" alt="" style=""></p><p>Create a class <code>MultiHeadAttention</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to perform multi head attention:</p><ul><li>Class constructor <code>def __init__(self, dm, h):</code><ul><li><code>dm</code> is an integer representing the dimensionality of the model</li><li><code>h</code> is an integer representing the number of heads</li><li><code>dm</code> is divisible by <code>h</code></li><li>Sets the following public instance attributes: <ul><li><code>h</code> - the number of heads</li><li><code>dm</code> - the dimensionality of the model</li><li><code>depth</code> - the depth of each attention head</li><li><code>Wq</code> - a Dense layer with <code>dm</code> units, used to generate the query matrix</li><li><code>Wk</code> - a Dense layer with <code>dm</code> units, used to generate the key matrix</li><li><code>Wv</code> - a Dense layer with <code>dm</code> units, used to generate the value matrix</li><li><code>linear</code> - a Dense layer with <code>dm</code> units, used to generate the attention output</li></ul></li></ul></li><li>Public instance method <code>def call(self, Q, K, V, mask):</code><ul><li><code>Q</code> is a tensor of shape <code>(batch, seq_len_q, dk)</code> containing the input to generate the query matrix</li><li><code>K</code> is a tensor of shape <code>(batch, seq_len_v, dk)</code> containing the input to generate the key matrix</li><li><code>V</code> is a tensor of shape <code>(batch, seq_len_v, dv)</code> containing the input to generate the value matrix</li><li><code>mask</code> is always <code>None</code></li><li>Returns: <code>output, weights</code><ul><li><code>output</code>a tensor with its last two dimensions as <code>(..., seq_len_q, dm)</code> containing the scaled dot product attention</li><li><code>weights</code> a tensor with its last three dimensions as <code>(..., h, seq_len_q, seq_len_v)</code> containing the attention weights</li></ul></li></ul></li><li>You can use <code>sdp_attention = __import__('5-sdp_attention').sdp_attention</code></li></ul><precode language="" precodenum="6"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>6-multihead_attention.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5426" data-toggle="modal" data-target="#task-5426-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5426-whiteboard-modal" data-task-id="5426">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "5. Multi Head Attention"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5426" data-toggle="modal" data-target="#task-test-correction-5426-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5427" data-position="8"><div class=" clearfix gap" id="task-5427"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5427"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5427" data-project-id="570" data-toggle="modal" data-target="#task-5427-users-done-modal"> Help </button></div><h4 class="task"> 6. Transformer Encoder Block <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/7/50a5309eae279760a5d6fc6031aa045eafd0e605.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200924%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200924T183051Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=d2b116a7d64f0397d0447e4cfc19f755258638fa5fdab562668da35425bfe0c7" alt="" style=""></p><p>Create a class <code>EncoderBlock</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to create an encoder block for a transformer:</p><ul><li>Class constructor <code>def __init__(self, dm, h, hidden, drop_rate=0.1):</code><ul><li><code>dm</code> - the dimensionality of the model</li><li><code>h</code> - the number of heads</li><li><code>hidden</code> - the number of hidden units in the fully connected layer</li><li><code>drop_rate</code> - the dropout rate</li><li>Sets the following public instance attributes: <ul><li><code>mha</code> - a <code>MultiHeadAttention</code> layer</li><li><code>dense_hidden</code> - the hidden dense layer with <code>hidden</code> units and <code>relu</code> activation</li><li><code>dense_output</code> - the output dense layer with <code>dm</code> units</li><li><code>layernorm1</code> - the first layer norm layer, with <code>epsilon=1e-6</code></li><li><code>layernorm2</code> - the second layer norm layer, with <code>epsilon=1e-6</code></li><li><code>dropout1</code> - the first dropout layer</li><li><code>dropout2</code> - the second dropout layer</li></ul></li></ul></li><li>Public instance method <code>call(self, x, training, mask=None):</code><ul><li><code>x</code> - a tensor of shape <code>(batch, input_seq_len, dm)</code>containing the input to the encoder block</li><li><code>training</code> - a boolean to determine if the model is training</li><li><code>mask</code> - the mask to be applied for multi head attention</li><li>Returns: a tensor of shape <code>(batch, input_seq_len, dm)</code> containing the block’s output</li></ul></li><li>You can use <code>MultiHeadAttention = __import__('6-multihead_attention').MultiHeadAttention</code></li></ul><precode language="" precodenum="7"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>7-transformer_encoder_block.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5427" data-toggle="modal" data-target="#task-5427-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5427-whiteboard-modal" data-task-id="5427">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "6. Transformer Encoder Block"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5427" data-toggle="modal" data-target="#task-test-correction-5427-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5428" data-position="9"><div class=" clearfix gap" id="task-5428"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5428"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5428" data-project-id="570" data-toggle="modal" data-target="#task-5428-users-done-modal"> Help </button></div><h4 class="task"> 7. Transformer Decoder Block <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>DecoderBlock</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to create an encoder block for a transformer:</p><ul><li>Class constructor <code>def __init__(self, dm, h, hidden, drop_rate=0.1):</code><ul><li><code>dm</code> - the dimensionality of the model</li><li><code>h</code> - the number of heads</li><li><code>hidden</code> - the number of hidden units in the fully connected layer</li><li><code>drop_rate</code> - the dropout rate</li><li>Sets the following public instance attributes: <ul><li><code>mha1</code> - the first <code>MultiHeadAttention</code> layer</li><li><code>mha2</code> - the second <code>MultiHeadAttention</code> layer</li><li><code>dense_hidden</code> - the hidden dense layer with <code>hidden</code> units and <code>relu</code> activation</li><li><code>dense_output</code> - the output dense layer with <code>dm</code> units</li><li><code>layernorm1</code> - the first layer norm layer, with <code>epsilon=1e-6</code></li><li><code>layernorm2</code> - the second layer norm layer, with <code>epsilon=1e-6</code></li><li><code>layernorm3</code> - the third layer norm layer, with <code>epsilon=1e-6</code></li><li><code>dropout1</code> - the first dropout layer</li><li><code>dropout2</code> - the second dropout layer</li><li><code>dropout3</code> - the third dropout layer</li></ul></li></ul></li><li>Public instance method <code>def call(self, x, encoder_output, training, look_ahead_mask, padding_mask):</code><ul><li><code>x</code> - a tensor of shape <code>(batch, target_seq_len, dm)</code>containing the input to the decoder block</li><li><code>encoder_output</code> - a tensor of shape <code>(batch, input_seq_len, dm)</code>containing the output of the encoder</li><li><code>training</code> - a boolean to determine if the model is training</li><li><code>look_ahead_mask</code> - the mask to be applied to the first multi head attention layer</li><li><code>padding_mask</code> - the mask to be applied to the second multi head attention layer</li><li>Returns: a tensor of shape <code>(batch, target_seq_len, dm)</code> containing the block’s output</li></ul></li><li>You can use <code>MultiHeadAttention = __import__('6-multihead_attention').MultiHeadAttention</code></li></ul><precode language="" precodenum="8"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>8-transformer_decoder_block.py</code></li></ul><div class="student_correction_requests"><!-- DISABLE UNTIL MIGRATION
        <button class="task_whiteboard_modal btn btn-default " data-task-id="5428" data-toggle="modal" data-target="#task-5428-whiteboard-modal">
          Whiteboard
        </button>
        <div class="modal fade task_whiteboard_modal" id="task-5428-whiteboard-modal" data-task-id="5428">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                <h4 class="modal-title">Your Notes on "7. Transformer Decoder Block"</h4>
            </div>
            <div class="modal-body">
                <div class="spinner gap">
                    <div class="bounce1"></div>
                    <div class="bounce2"></div>
                    <div class="bounce3"></div>
                </div>
                <div class="task-note-prompts-and-placeholders-container">
                    <button type="button" class="whiteboard-submit-button btn btn-primary">Submit</button>
                </div>
            </div>
        </div>
    </div>
</div>

      --><!-- Button test code --><button class="task_correction_modal btn btn-default " data-task-id="5428" data-toggle="modal" data-target="#task-test-correction-5428-correction-modal"> Check your code? </button><!-- Button containers --><!-- Button for QA Review --></div></div></div><div data-role="task5429" data-position="10"><div class=" clearfix gap" id="task-5429"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5429"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5429" data-project-id="570" data-toggle="modal" data-target="#task-5429-users-done-modal"> Help </button></div><h4 class="task"> 8. Transformer Encoder <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>Encoder</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to create the encoder for a transformer:</p><ul><li>Class constructor <code>def __init__(self, N, dm, h, hidden, input_vocab, max_seq_len, drop_rate=0.1):</code><ul><li><code>N</code> - the number of blocks in the encoder</li><li><code>dm</code> - the dimensionality of the model</li><li><code>h</code> - the number of heads</li><li><code>hidden</code> - the number of hidden units in the fully connected layer</li><li><code>input_vocab</code> - the size of the input vocabulary</li><li><code>max_seq_len</code> - the maximum sequence length possible</li><li><code>drop_rate</code> - the dropout rate</li><li>Sets the following public instance attributes: <ul><li><code>N</code> - the number of blocks in the encoder</li><li><code>dm</code> - the dimensionality of the model</li><li><code>embedding</code> - the embedding layer for the inputs</li><li><code>positional_encoding</code> - a <code>numpy.ndarray</code> of shape <code>(max_seq_len, dm)</code> containing the positional encodings</li><li><code>blocks</code> - a list of length <code>N</code> containing all of the <code>EncoderBlock</code>‘s</li><li><code>dropout</code> - the dropout layer, to be applied to the positional encodings</li></ul></li></ul></li><li>Public instance method <code>call(self, x, training, mask):</code><ul><li><code>x</code> - a tensor of shape <code>(batch, input_seq_len, dm)</code>containing the input to the encoder</li><li><code>training</code> - a boolean to determine if the model is training</li><li><code>mask</code> - the mask to be applied for multi head attention</li><li>Returns: a tensor of shape <code>(batch, input_seq_len, dm)</code> containing the encoder output</li></ul></li><li>You can use <code>positional_encoding = __import__('4-positional_encoding').positional_encoding</code> and <code>EncoderBlock = __import__('7-transformer_encoder_block').EncoderBlock</code></li></ul><precode language="" precodenum="9"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>9-transformer_encoder.py</code></li></ul></div></div><div data-role="task5430" data-position="11"><div class=" clearfix gap" id="task-5430"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5430"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5430" data-project-id="570" data-toggle="modal" data-target="#task-5430-users-done-modal"> Help </button></div><h4 class="task"> 9. Transformer Decoder <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>Decoder</code> that inherits from <code>tensorflow.keras.layers.Layer</code> to create the decoder for a transformer:</p><ul><li>Class constructor <code>def __init__(self, N, dm, h, hidden, target_vocab, max_seq_len, drop_rate=0.1):</code></li><li><code>N</code> - the number of blocks in the encoder <ul><li><code>dm</code> - the dimensionality of the model</li><li><code>h</code> - the number of heads</li><li><code>hidden</code> - the number of hidden units in the fully connected layer</li><li><code>target_vocab</code> - the size of the target vocabulary</li><li><code>max_seq_len</code> - the maximum sequence length possible</li><li><code>drop_rate</code> - the dropout rate</li><li>Sets the following public instance attributes: <ul><li><code>N</code> - the number of blocks in the encoder</li><li><code>dm</code> - the dimensionality of the model</li><li><code>embedding</code> - the embedding layer for the targets</li><li><code>positional_encoding</code> - a <code>numpy.ndarray</code> of shape <code>(max_seq_len, dm)</code> containing the positional encodings</li><li><code>blocks</code> - a list of length <code>N</code> containing all of the <code>DecoderBlock</code>‘s</li><li><code>dropout</code> - the dropout layer, to be applied to the positional encodings</li></ul></li></ul></li><li>Public instance method <code>def call(self, x, encoder_output, training, look_ahead_mask, padding_mask):</code><ul><li><code>x</code> - a tensor of shape <code>(batch, target_seq_len, dm)</code>containing the input to the decoder</li><li><code>encoder_output</code> - a tensor of shape <code>(batch, input_seq_len, dm)</code>containing the output of the encoder</li><li><code>training</code> - a boolean to determine if the model is training</li><li><code>look_ahead_mask</code> - the mask to be applied to the first multi head attention layer</li><li><code>padding_mask</code> - the mask to be applied to the second multi head attention layer</li><li>Returns: a tensor of shape <code>(batch, target_seq_len, dm)</code> containing the decoder output</li></ul></li><li>You can use <code>positional_encoding = __import__('4-positional_encoding').positional_encoding</code> and <code>DecoderBlock = __import__('8-transformer_decoder_block').DecoderBlock</code></li></ul><precode language="" precodenum="10"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>10-transformer_decoder.py</code></li></ul></div></div><div data-role="task5431" data-position="12"><div class=" clearfix gap" id="task-5431"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="5431"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="5431" data-project-id="570" data-toggle="modal" data-target="#task-5431-users-done-modal"> Help </button></div><h4 class="task"> 10. Transformer Network <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create a class <code>Transformer</code> that inherits from <code>tensorflow.keras.Model</code> to create a transformer network:</p><ul><li>Class constructor <code>def __init__(self, N, dm, h, hidden, input_vocab, target_vocab, max_seq_input, max_seq_target, drop_rate=0.1):</code><ul><li><code>N</code> - the number of blocks in the encoder and decoder</li><li><code>dm</code> - the dimensionality of the model</li><li><code>h</code> - the number of heads</li><li><code>hidden</code> - the number of hidden units in the fully connected layers</li><li><code>input_vocab</code> - the size of the input vocabulary</li><li><code>target_vocab</code> - the size of the target vocabulary</li><li><code>max_seq_input</code> - the maximum sequence length possible for the input</li><li><code>max_seq_target</code> - the maximum sequence length possible for the target</li><li><code>drop_rate</code> - the dropout rate</li><li>Sets the following public instance attributes: <ul><li><code>encoder</code> - the encoder layer</li><li><code>decoder</code> - the decoder layer</li><li><code>linear</code> - a final Dense layer with <code>target_vocab</code> units</li></ul></li></ul></li><li>Public instance method <code>def call(self, inputs, target, training, encoder_mask, look_ahead_mask, decoder_mask):</code><ul><li><code>inputs</code> - a tensor of shape <code>(batch, input_seq_len, dm)</code>containing the inputs</li><li><code>target</code> - a tensor of shape <code>(batch, target_seq_len, dm)</code>containing the target</li><li><code>training</code> - a boolean to determine if the model is training</li><li><code>encoder_mask</code> - the padding mask to be applied to the encoder</li><li><code>look_ahead_mask</code> - the look ahead mask to be applied to the decoder</li><li><code>decoder_mask</code> - the padding mask to be applied to the decoder</li><li>Returns: a tensor of shape <code>(batch, target_seq_len, target_vocab)</code> containing the transformer output</li></ul></li><li>You can use <code>Encoder = __import__('9-transformer_encoder').Encoder</code> and <code>Decoder = __import__('10-transformer_decoder').Decoder</code></li></ul><precode language="" precodenum="11"></precode><p><em>Ignore the Warning messages in the output</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x11-attention</code></li><li>File: <code>11-transformer.py</code></li></ul></div></div></section></article>
