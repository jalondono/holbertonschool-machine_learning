<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x12. Transformer Applications</h1><div id="project_id" style="display: none" data-project-id="853"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning ― Supervised Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 09-30-2020, must end by 10-07-2020 (in 7 days) - you're done with <span id="student_task_done_percentage">0</span>% of tasks. </small></p><p><small><i class="fa fa-check-square"></i> QA review fully automated. </small></p><article id="description" class="gap formatted-content"><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/9/2b6bbd4de27e8b9b147fb397906ee5e822fe6fa3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200930%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200930T131511Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=fe7607dca02b9109345ea4e180c3080dc0ed1cdf2ad003fb6866d42d3bc0ec46" alt="" style=""></p><h2>Resources</h2><p><strong>Read or watch:</strong></p><ul><li><a href="/rltoken/jxxAqYmZVG_896LjsHA0SA" title="TFDS Overview" target="_blank">TFDS Overview</a></li><li><a href="/rltoken/3jhsMi8_VIZd2uzlyN-SaQ" title="TFDS Keras Example" target="_blank">TFDS Keras Example</a></li><li><a href="/rltoken/PBFAFa4q7sbMhLyrBg84Xg" title="Customizing what happens in fit" target="_blank">Customizing what happens in fit</a></li></ul><p><strong>References:</strong></p><ul><li><a href="/rltoken/_Sot-yIEG4acO7oABwji-Q" title="tfds" target="_blank">tfds</a><ul><li><a href="/rltoken/zlfIaVsEPgK3M-PFqYx8kw" title="tfds.load" target="_blank">tfds.load</a></li><li><a href="/rltoken/pVFn4RX89X8AK9l1CICrZw" title="tfds.features.text.SubwordTextEncoder" target="_blank">tfds.features.text.SubwordTextEncoder</a></li></ul></li><li><a href="/rltoken/C1R6GSnrg7By7F1ZozYALQ" title="tf.py_function" target="_blank">tf.py_function</a></li><li><a href="/rltoken/4EiwSWc51djgL5YL8CPyWw" title="tf.linalg.band_part" target="_blank">tf.linalg.band_part</a></li></ul><h2>Learning Objectives</h2><p>At the end of this project, you are expected to be able to <a href="/rltoken/_8t31BZ1oiscVowS0fV5xw" title="explain to anyone" target="_blank">explain to anyone</a>, <strong>without the help of Google</strong>:</p><h3>General</h3><ul><li>How to use Transformers for Machine Translation</li><li>How to write a custom train/test loop in Keras</li><li>How to use Tensorflow Datasets</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.16) and <code>tensorflow</code> (version 1.15)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>All of your files must be executable</li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should follow the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li><li>Unless otherwise stated, you cannot import any module except <code>import tensorflow.compat.v2 as tf</code></li></ul><h2>TF Datasets</h2><p>For machine translation, we will be using the prepared <a href="/rltoken/JpNiruFnMoCN2ElftkLWUw" title="Tensorflow Datasets" target="_blank">Tensorflow Datasets</a>¨NBSP;<a href="/rltoken/w3kBudIiwPqWRxfTEld95g" title="ted_hrlr_translate/pt_to_en" target="_blank">ted_hrlr_translate/pt_to_en</a> for English to Portuguese translation</p><p>To download Tensorflow Datasets, please use:</p><precode language="" precodenum="0"></precode><p>To use this dataset, we will have to use the Tensorflow 2.0 compat within Tensorflow 1.15 and download the content:</p><precode language="" precodenum="1"></precode></article><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task7113" data-position="1"><div class=" clearfix gap" id="task-7113"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7113"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7113" data-project-id="853" data-toggle="modal" data-target="#task-7113-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7113-users-done-modal" data-task-id="7113" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "0. Dataset"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 0. Dataset <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create the class <code>Dataset</code> that loads and preps a dataset for machine translation:</p><ul><li>Class constructor <code>def __init__(self):</code><ul><li>creates the instance attributes: <ul><li><code>data_train</code>, which contains the <code>ted_hrlr_translate/pt_to_en</code><code>tf.data.Dataset</code><code>train</code> split, loaded <code>as_supervided</code></li><li><code>data_valid</code>, which contains the <code>ted_hrlr_translate/pt_to_en</code><code>tf.data.Dataset</code><code>validate</code> split, loaded <code>as_supervided</code></li><li><code>tokenizer_pt</code> is the Portuguese tokenizer created from the training set</li><li><code>tokenizer_en</code> is the English tokenizer created from the training set</li></ul></li></ul></li><li>Create the instance method <code>def tokenize_dataset(self, data):</code> that creates sub-word tokenizers for our dataset: <ul><li><code>data</code> is a <code>tf.data.Dataset</code> whose examples are formatted as a tuple <code>(pt, en)</code><ul><li><code>pt</code> is the <code>tf.Tensor</code> containing the Portuguese sentence</li><li><code>en</code> is the <code>tf.Tensor</code> containing the corresponding English sentence</li></ul></li><li>The maximum vocab size should be set to <code>2**15</code></li><li>Returns: <code>tokenizer_pt, tokenizer_en</code><ul><li><code>tokenizer_pt</code> is the Portuguese tokenizer</li><li><code>tokenizer_en</code> is the English tokenizer</li></ul></li></ul></li></ul><precode language="" precodenum="2"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>0-dataset.py</code></li></ul></div></div><div data-role="task7114" data-position="2"><div class=" clearfix gap" id="task-7114"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7114"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7114" data-project-id="853" data-toggle="modal" data-target="#task-7114-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7114-users-done-modal" data-task-id="7114" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "1. Encode Tokens"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 1. Encode Tokens <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Update the class <code>Dataset</code>:</p><ul><li>Create the instance method <code>def encode(self, pt, en):</code> that encodes a translation into tokens: <ul><li><code>pt</code> is the <code>tf.Tensor</code> containing the Portuguese sentence</li><li><code>en</code> is the <code>tf.Tensor</code> containing the corresponding English sentence</li><li>The tokenized sentences should include the start and end of sentence tokens</li><li>The start token should be indexed as <code>vocab_size</code></li><li>The end token should be indexed as <code>vocab_size + 1</code></li><li>Returns: <code>pt_tokens, en_tokens</code><ul><li><code>pt_tokens</code> is a <code>tf.Tensor</code> containing the Portuguese tokens</li><li><code>en_tokens</code> is a <code>tf.Tensor</code> containing the English tokens</li></ul></li></ul></li></ul><precode language="" precodenum="3"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>1-dataset.py</code></li></ul></div></div><div data-role="task7115" data-position="3"><div class=" clearfix gap" id="task-7115"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7115"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7115" data-project-id="853" data-toggle="modal" data-target="#task-7115-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7115-users-done-modal" data-task-id="7115" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "2. TF Encode"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 2. TF Encode <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Update the class <code>Dataset</code>:</p><ul><li>Create the instance method <code>def tf_encode(self, pt, en):</code> that acts as a <code>tensorflow</code> wrapper for the <code>encode</code> instance method <ul><li>Make sure to set the shape of the <code>pt</code> and <code>en</code> return tensors</li></ul></li><li>Update the class constructor <code>def __init__(self):</code><ul><li>update the <code>data_train</code> and <code>data_validate</code> attributes by tokenizing the examples</li></ul></li></ul><precode language="" precodenum="4"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>2-dataset.py</code></li></ul></div></div><div data-role="task7116" data-position="4"><div class=" clearfix gap" id="task-7116"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7116"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7116" data-project-id="853" data-toggle="modal" data-target="#task-7116-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7116-users-done-modal" data-task-id="7116" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "3. Pipeline"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 3. Pipeline <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Update the class <code>Dataset</code> to set up the data pipeline:</p><ul><li>Update the class constructor <code>def __init__(self, batch_size, max_len):</code><ul><li><code>batch_size</code> is the batch size for training/validation</li><li><code>max_len</code> is the maximum number of tokens allowed per example sentence</li><li>update the <code>data_train</code> attribute by performing the following actions: <ul><li>filter out all examples that have either sentence with more than <code>max_len</code> tokens</li><li>cache the dataset to increase performance</li><li>shuffle the entire dataset</li><li>split the dataset into padded batches of size <code>batch_size</code></li><li>prefetch the dataset using <code>tf.data.experimental.AUTOTUNE</code> to increase performance</li></ul></li><li>update the <code>data_validate</code> attribute by performing the following actions: <ul><li>filter out all examples that have either sentence with more than <code>max_len</code> tokens</li><li>split the dataset into padded batches of size <code>batch_size</code></li></ul></li></ul></li></ul><precode language="" precodenum="5"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>3-dataset.py</code></li></ul></div></div><div data-role="task7117" data-position="5"><div class=" clearfix gap" id="task-7117"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7117"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7117" data-project-id="853" data-toggle="modal" data-target="#task-7117-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7117-users-done-modal" data-task-id="7117" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "4. Create Masks"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 4. Create Masks <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Create the function <code>def create_masks(inputs, target):</code> that creates all masks for training/validation:</p><ul><li><code>inputs</code> is a tf.Tensor of shape <code>(batch_size, seq_len_in)</code> that contains the input sentence</li><li><code>target</code> is a tf.Tensor of shape <code>(batch_size, seq_len_out)</code> that contains the target sentence</li><li>This function should only use <code>tensorflow</code> operations in order to properly function in the training step</li><li>Returns: <code>encoder_mask</code>, <code>look_ahead_mask</code>, <code>decoder_mask</code><ul><li><code>encoder_mask</code> is the <code>tf.Tensor</code> padding mask of shape <code>(batch_size, 1, 1, seq_len_in)</code> to be applied in the encoder</li><li><code>look_ahead_mask</code> is the <code>tf.Tensor</code> look ahead mask of shape <code>(batch_size, 1, seq_len_out, seq_len_out)</code> to be applied in the decoder </li><li><code>decoder_mask</code> is the <code>tf.Tensor</code> padding mask of shape <code>(batch_size, 1, 1, seq_len_in)</code> to be applied in the decoder</li></ul></li></ul><precode language="" precodenum="6"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>4-create_masks.py</code></li></ul></div></div><div data-role="task7118" data-position="6"><div class=" clearfix gap" id="task-7118"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="7118"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="7118" data-project-id="853" data-toggle="modal" data-target="#task-7118-users-done-modal"> Help </button><div class="modal fade users-done-modal" id="task-7118-users-done-modal" data-task-id="7118" data-project-id="853"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button><h4 class="modal-title">Students who are done with "5. Train"</h4></div><div class="modal-body"><div class="list-group"></div><div class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="error"></div></div></div></div></div></div><h4 class="task"> 5. Train <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Take your implementation of a transformer from our <a href="/rltoken/xFGAKD-jaUWnsvOXMTPcvw" title="previous project" target="_blank">previous project</a> and save it to the file <code>5-transformer.py</code>. Note, you may need to make slight adjustments to this model to get it to functionally train.</p><p>Write a the function <code>def train_transformer(N, dm, h, hidden, max_len, batch_size, epochs):</code> that creates and trains a transformer model for machine translation of Portuguese to English using our previously created dataset:</p><ul><li><code>N</code> the number of blocks in the encoder and decoder</li><li><code>dm</code> the dimensionality of the model</li><li><code>h</code> the number of heads</li><li><code>hidden</code> the number of hidden units in the fully connected layers</li><li><code>max_len</code> the maximum number of tokens per sequence</li><li><code>batch_size</code> the batch size for training</li><li><code>epochs</code> the number of epochs to train for</li><li>You should use the following imports: <ul><li><code>Dataset = __import__('3-dataset').Dataset</code></li><li><code>create_masks = __import__('4-create_masks').create_masks</code></li><li><code>Transformer = __import__('5-transformer').Transformer</code></li></ul></li><li>Your model should be trained with Adam optimization and sparse categorical crossentropy</li><li>Your model should show the metrics </li><li>Your model should print information about the training every 50 batches and every epoch, formatted as shown in the example below</li><li>Returns the trained model</li></ul><precode language="" precodenum="7"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>supervised_learning/0x12-transformer_apps</code></li><li>File: <code>5-transformer.py, 5-train.py</code></li></ul></div></div></section></article>

