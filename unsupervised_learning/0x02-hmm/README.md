<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x02. Hidden Markov Models</h1><div id="project_id" style="display: none" data-project-id="542"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning â€• Unsupervised Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 08-10-2020, must end by 08-15-2020 (in 4 days) - you're done with <span id="student_task_done_percentage">0</span>% of tasks. </small></p><p><small><i class="fa fa-check"></i> Checker will be released at 08-12-2020 12:00 PM </small></p><p><small><i class="fa fa-check-square"></i> QA review fully automated. </small></p><article id="description" class="gap formatted-content"><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/1/027d4a67aea17e6fa181.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200810T210610Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=9d1e16d3939f4337cada0891a4260fcd79b272906c23121f3024d0e4a2a0cd2c" alt="" style=""></p><h2>Resources</h2><p><strong>Read or watch</strong>:</p><ul><li><a href="/rltoken/F7v-6UX8GSo7tcrLuj3pTg" title="Markov property" target="_blank">Markov property</a></li><li><a href="/rltoken/pJySWk8zYyiFBbXha1v9Uw" title="Markov Chain" target="_blank">Markov Chain</a></li><li><a href="/rltoken/tJPuYPGZmTCCiajHOHzHPg" title="Properties of Markov Chains" target="_blank">Properties of Markov Chains</a></li><li><a href="/rltoken/ek3QosV9fS9Ep7hF7Z8UNA" title="Markov Chains" target="_blank">Markov Chains</a></li><li><a href="/rltoken/ismECln2KQ_NWqlhDi4SOA" title="Markov Matrices" target="_blank">Markov Matrices</a></li><li><a href="/rltoken/-P79YH94sPDmW3witwXEgA" title="1.3 Convergence of Regular Markov Chains" target="_blank">1.3 Convergence of Regular Markov Chains</a></li><li><a href="/rltoken/Gphacn9fdFCQFGMeMyYxlg" title="Markov Chains, Part 1" target="_blank">Markov Chains, Part 1</a></li><li><a href="/rltoken/flDg5iw0va1FhUjsMFHgdg" title="Markov Chains, Part 2" target="_blank">Markov Chains, Part 2</a></li><li><a href="/rltoken/zRg0ddD8arH7F1hiOlaNiA" title="Markov Chains, Part 3" target="_blank">Markov Chains, Part 3</a></li><li><a href="/rltoken/AD3VcrR0vmdPkLIHFCWd2Q" title="Markov Chains, Part 4" target="_blank">Markov Chains, Part 4</a></li><li><a href="/rltoken/V7XdIdjg5NJpuWgV_tVk3A" title="Markov Chains, Part 5" target="_blank">Markov Chains, Part 5</a></li><li><a href="/rltoken/Iyup5UA69u1UYzIsgcn4Fg" title="Markov Chains, Part 7" target="_blank">Markov Chains, Part 7</a></li><li><a href="/rltoken/wXvkFVOTl3NOKWgT63odOw" title="Markov Chains, Part 8" target="_blank">Markov Chains, Part 8</a></li><li><a href="/rltoken/Qg8C9pzP1Yr4P8bxECb7pQ" title="Hidden Markov model" target="_blank">Hidden Markov model</a></li><li><a href="/rltoken/D4kPhrRbShrDWSANnlJdkQ" title="Hidden Markov Models" target="_blank">Hidden Markov Models</a></li><li><a href="/rltoken/CpcwO0SbMD05S7IOfc3jeA" title="(ML 14.1) Markov models - motivating examples" target="_blank">(ML 14.1) Markov models - motivating examples</a></li><li><a href="/rltoken/C-TgJ6CKgBUbL3yxfvJHqA" title="(ML 14.2) Markov chains (discrete-time) (part 1)" target="_blank">(ML 14.2) Markov chains (discrete-time) (part 1)</a></li><li><a href="/rltoken/zMjTTG-qtP0QfcbYXFujUg" title="(ML 14.3) Markov chains (discrete-time) (part 2)" target="_blank">(ML 14.3) Markov chains (discrete-time) (part 2)</a></li><li><a href="/rltoken/tMsk_K-n0mYOtsthhBrQcg" title="(ML 14.4) Hidden Markov models (HMMs) (part 1)" target="_blank">(ML 14.4) Hidden Markov models (HMMs) (part 1)</a></li><li><a href="/rltoken/2k8q4yyclHlMoE83WhKf8g" title="(ML 14.5) Hidden Markov models (HMMs) (part 2)" target="_blank">(ML 14.5) Hidden Markov models (HMMs) (part 2)</a></li><li><a href="/rltoken/Qljf3X5iH7oaKWuF2I165A" title="(ML 14.6) Forward-Backward algorithm for HMMs" target="_blank">(ML 14.6) Forward-Backward algorithm for HMMs</a></li><li><a href="/rltoken/Tc6D_BMgvdxMWGoBtvo-Nw" title="(ML 14.7) Forward algorithm (part 1)" target="_blank">(ML 14.7) Forward algorithm (part 1)</a></li><li><a href="/rltoken/AMUSX-wBTAeTsvJKFlOiIQ" title="(ML 14.8) Forward algorithm (part 2)" target="_blank">(ML 14.8) Forward algorithm (part 2)</a></li><li><a href="/rltoken/GuKHZZ4HNUS-xnbwBf8YsQ" title="(ML 14.9) Backward algorithm" target="_blank">(ML 14.9) Backward algorithm</a></li><li><a href="/rltoken/uZ3KdzsuS0YmbvxDD2G-NQ" title="(ML 14.10) Underflow and the log-sum-exp trick" target="_blank">(ML 14.10) Underflow and the log-sum-exp trick</a></li><li><a href="/rltoken/UAmz_LJdG5w3sS_8xSAsGg" title="(ML 14.11) Viterbi algorithm (part 1)" target="_blank">(ML 14.11) Viterbi algorithm (part 1)</a></li><li><a href="/rltoken/c0LxuyQ8HeprSObqEVkTQA" title="(ML 14.12) Viterbi algorithm (part 2)" target="_blank">(ML 14.12) Viterbi algorithm (part 2)</a></li></ul><h2>Learning Objectives</h2><ul><li>What is the Markov property?</li><li>What is a Markov chain?</li><li>What is a state?</li><li>What is a transition probability/matrix?</li><li>What is a stationary state?</li><li>What is a regular Markov chain?</li><li>How to determine if a transition matrix is regular</li><li>What is an absorbing state?</li><li>What is a transient state?</li><li>What is a recurrent state?</li><li>What is an absorbing Markov chain?</li><li>What is a Hidden Markov Model?</li><li>What is a hidden state?</li><li>What is an observation?</li><li>What is an emission probability/matrix?</li><li>What is a Trellis diagram?</li><li>What is the Forward algorithm and how do you implement it?</li><li>What is decoding?</li><li>What is the Viterbi algorithm and how do you implement it?</li><li>What is the Forward-Backward algorithm and how do you implement it?</li><li>What is the Baum-Welch algorithm and how do you implement it?</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.15)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should use the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li><li>Unless otherwise noted, you are not allowed to import any module except <code>import numpy as np</code></li><li>All your files must be executable</li></ul></article><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task4660" data-position="1"><div class=" clearfix gap" id="task-4660"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4660"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4660" data-project-id="542" data-toggle="modal" data-target="#task-4660-users-done-modal"> Help </button></div><h4 class="task"> 0. Markov Chain <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def markov_chain(P, s, t=1):</code> that determines the probability of a markov chain being in a particular state after a specified number of iterations:</p><ul><li><code>P</code> is a square 2D <code>numpy.ndarray</code> of shape <code>(n, n)</code> representing the transition matrix <ul><li><code>P[i, j]</code> is the probability of transitioning from state <code>i</code> to state <code>j</code></li><li><code>n</code> is the number of states in the markov chain</li></ul></li><li><code>s</code> is a <code>numpy.ndarray</code> of shape <code>(1, n)</code> representing the probability of starting in each state</li><li><code>t</code> is the number of iterations that the markov chain has been through</li><li>Returns: a <code>numpy.ndarray</code> of shape <code>(1, n)</code> representing the probability of being in a specific state after <code>t</code> iterations, or <code>None</code> on failure</li></ul><precode language="" precodenum="0"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>0-markov_chain.py</code></li></ul></div></div><div data-role="task4661" data-position="2"><div class=" clearfix gap" id="task-4661"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4661"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4661" data-project-id="542" data-toggle="modal" data-target="#task-4661-users-done-modal"> Help </button></div><h4 class="task"> 1. Regular Chains <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def regular(P):</code> that determines the steady state probabilities of a regular markov chain:</p><ul><li><code>P</code> is a is a square 2D <code>numpy.ndarray</code> of shape <code>(n, n)</code> representing the transition matrix <ul><li><code>P[i, j]</code> is the probability of transitioning from state <code>i</code> to state <code>j</code></li><li><code>n</code> is the number of states in the markov chain</li></ul></li><li>Returns: a <code>numpy.ndarray</code> of shape <code>(1, n)</code> containing the steady state probabilities, or <code>None</code> on failure</li></ul><precode language="" precodenum="1"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>1-regular.py</code></li></ul></div></div><div data-role="task4662" data-position="3"><div class=" clearfix gap" id="task-4662"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4662"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4662" data-project-id="542" data-toggle="modal" data-target="#task-4662-users-done-modal"> Help </button></div><h4 class="task"> 2. Absorbing Chains <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def absorbing(P):</code> that determines if a markov chain is absorbing:</p><ul><li>P is a is a square 2D <code>numpy.ndarray</code> of shape <code>(n, n)</code> representing the transition matrix <ul><li><code>P[i, j]</code> is the probability of transitioning from state <code>i</code> to state <code>j</code></li><li><code>n</code> is the number of states in the markov chain</li></ul></li><li>Returns: <code>True</code> if it is absorbing, or <code>False</code> on failure</li></ul><precode language="" precodenum="2"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>2-absorbing.py</code></li></ul></div></div><div data-role="task4663" data-position="4"><div class=" clearfix gap" id="task-4663"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4663"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4663" data-project-id="542" data-toggle="modal" data-target="#task-4663-users-done-modal"> Help </button></div><h4 class="task"> 3. The Forward Algorithm <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/1/a4a616525a089952d29f.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200810T210610Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ea80d355635fe00531f93bd82c5f3679dacb1b3a7cb4cc532a6ebfe3c962741e" alt="" style=""></p><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/1/f847db61fbc52eda75d9.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200810T210610Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=91f881b9b7184b3b9ec706380d46c7ab6c3977d0b9df37a481654d5ffdedd18b" alt="" style=""></p><p>Write the function <code>def forward(Observation, Emission, Transition, Initial):</code> that performs the forward algorithm for a hidden markov model:</p><ul><li><code>Observation</code> is a <code>numpy.ndarray</code> of shape <code>(T,)</code> that contains the index of the observation <ul><li><code>T</code> is the number of observations</li></ul></li><li><code>Emission</code> is a <code>numpy.ndarray</code> of shape <code>(N, M)</code> containing the emission probability of a specific observation given a hidden state <ul><li><code>Emission[i, j]</code> is the probability of observing <code>j</code> given the hidden state <code>i</code></li><li><code>N</code> is the number of hidden states</li><li><code>M</code> is the number of all possible observations</li></ul></li><li><code>Transition</code> is a 2D <code>numpy.ndarray</code> of shape <code>(N, N)</code> containing the transition probabilities <ul><li><code>Transition[i, j]</code> is the probability of transitioning from the hidden state <code>i</code> to <code>j</code></li></ul></li><li><code>Initial</code> a <code>numpy.ndarray</code> of shape <code>(N, 1)</code> containing the probability of starting in a particular hidden state</li><li>Returns: <code>P, F</code>, or <code>None, None</code> on failure <ul><li><code>P</code> is the likelihood of the observations given the model</li><li><code>F</code> is a <code>numpy.ndarray</code> of shape <code>(N, T)</code> containing the forward path probabilities <ul><li><code>F[i, j]</code> is the probability of being in hidden state <code>i</code> at time <code>j</code> given the previous observations</li></ul></li></ul></li></ul><precode language="" precodenum="3"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>3-forward.py</code></li></ul></div></div><div data-role="task4664" data-position="5"><div class=" clearfix gap" id="task-4664"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4664"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4664" data-project-id="542" data-toggle="modal" data-target="#task-4664-users-done-modal"> Help </button></div><h4 class="task"> 4. The Viretbi Algorithm <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def viterbi(Observation, Emission, Transition, Initial):</code> that calculates the most likely sequence of hidden states for a hidden markov model:</p><ul><li><code>Observation</code> is a <code>numpy.ndarray</code> of shape <code>(T,)</code> that contains the index of the observation <ul><li><code>T</code> is the number of observations</li></ul></li><li><code>Emission</code> is a <code>numpy.ndarray</code> of shape <code>(N, M)</code> containing the emission probability of a specific observation given a hidden state <ul><li><code>Emission[i, j]</code> is the probability of observing <code>j</code> given the hidden state <code>i</code></li><li><code>N</code> is the number of hidden states</li><li><code>M</code> is the number of all possible observations</li></ul></li><li><code>Transition</code> is a 2D <code>numpy.ndarray</code> of shape <code>(N, N)</code> containing the transition probabilities <ul><li><code>Transition[i, j]</code> is the probability of transitioning from the hidden state <code>i</code> to <code>j</code></li></ul></li><li><code>Initial</code> a <code>numpy.ndarray</code> of shape <code>(N, 1)</code> containing the probability of starting in a particular hidden state</li><li>Returns: <code>path, P</code>, or <code>None, None</code> on failure <ul><li><code>path</code> is the a list of length <code>T</code> containing the most likely sequence of hidden states</li><li><code>P</code> is the probability of obtaining the <code>path</code> sequence</li></ul></li></ul><precode language="" precodenum="4"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>4-viterbi.py</code></li></ul></div></div><div data-role="task4665" data-position="6"><div class=" clearfix gap" id="task-4665"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4665"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4665" data-project-id="542" data-toggle="modal" data-target="#task-4665-users-done-modal"> Help </button></div><h4 class="task"> 5. The Backward Algorithm <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def backward(Observation, Emission, Transition, Initial):</code> that performs the backward algorithm for a hidden markov model:</p><ul><li><code>Observation</code> is a <code>numpy.ndarray</code> of shape <code>(T,)</code> that contains the index of the observation <ul><li><code>T</code> is the number of observations</li></ul></li><li><code>Emission</code> is a <code>numpy.ndarray</code> of shape <code>(N, M)</code> containing the emission probability of a specific observation given a hidden state <ul><li><code>Emission[i, j]</code> is the probability of observing <code>j</code> given the hidden state <code>i</code></li><li><code>N</code> is the number of hidden states</li><li><code>M</code> is the number of all possible observations</li></ul></li><li><code>Transition</code> is a 2D <code>numpy.ndarray</code> of shape <code>(N, N)</code> containing the transition probabilities <ul><li><code>Transition[i, j]</code> is the probability of transitioning from the hidden state <code>i</code> to <code>j</code></li></ul></li><li><code>Initial</code> a <code>numpy.ndarray</code> of shape <code>(N, 1)</code> containing the probability of starting in a particular hidden state</li><li>Returns: <code>P, B</code>, or <code>None, None</code> on failure <ul><li><code>P</code>is the likelihood of the observations given the model</li><li><code>B</code> is a <code>numpy.ndarray</code> of shape <code>(N, T)</code> containing the backward path probabilities <ul><li><code>B[i, j]</code> is the probability of generating the future observations from hidden state <code>i</code> at time <code>j</code></li></ul></li></ul></li></ul><precode language="" precodenum="5"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>5-backward.py</code></li></ul></div></div><div data-role="task4666" data-position="7"><div class=" clearfix gap" id="task-4666"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="4666"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="4666" data-project-id="542" data-toggle="modal" data-target="#task-4666-users-done-modal"> Help </button></div><h4 class="task"> 6. The Baum-Welch Algorithm <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def baum_welch(Observations, Transition, Emission, Initial, iterations=1000):</code> that performs the Baum-Welch algorithm for a hidden markov model:</p><ul><li><code>Observations</code> is a <code>numpy.ndarray</code> of shape <code>(T,)</code> that contains the index of the observation <ul><li><code>T</code> is the number of observations</li></ul></li><li><code>Transition</code> is a <code>numpy.ndarray</code> of shape <code>(M, M)</code> that contains the initialized transition probabilities <ul><li><code>M</code> is the number of hidden states</li></ul></li><li><code>Emission</code> is a <code>numpy.ndarray</code> of shape <code>(M, N)</code> that contains the initialized emission probabilities <ul><li><code>N</code> is the number of output states</li></ul></li><li><code>Initial</code> is a <code>numpy.ndarray</code> of shape <code>(M, 1)</code> that contains the initialized starting probabilities</li><li><code>iterations</code> is the number of times expectation-maximization should be performed</li><li>Returns: the converged <code>Transition, Emission</code>, or <code>None, None</code> on failure</li></ul><precode language="" precodenum="6"></precode><p><em>With very little data (only 365 observations), we have been able to get a pretty good estimate of the transition and emission probabilities. We have not used a larger sample size in this example because our implementation does not utilize logarithms to handle values approaching 0 with the increased sequence length</em></p><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>unsupervised_learning/0x02-hmm</code></li><li>File: <code>6-baum_welch.py</code></li></ul></div></div></section></article>

