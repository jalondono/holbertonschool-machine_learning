<article class=""><div id="jigsaw-shortcut-lists"></div><h1 class="gap">0x00. Q-learning</h1><div id="project_id" style="display: none" data-project-id="783"></div><p class="sm-gap"><small><i class="fa fa-folder-open"></i> Specializations - Machine Learning ― Reinforcement Learning </small></p><p><em><small><i class="fa fa-user"></i> by Alexa Orrico, Software Engineer at Holberton School </small></em></p><p><small><i class="fa fa-calendar"></i> Ongoing project - started 09-28-2020, must end by 09-30-2020 (in 1 day) - you're done with <span id="student_task_done_percentage">0</span>% of tasks. </small></p><p><small><i class="fa fa-check-square"></i><strong>Manual QA review must be done</strong> (request it when you are done with the project) </small></p><article id="description" class="gap formatted-content"><p><img src="https://holbertonintranet.s3.amazonaws.com/uploads/medias/2020/8/5478322429e44f196aff6896f42ce2ea0741ba36.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIARDDGGGOUWMNL5ANN%2F20200928%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200928T201834Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=11c6774af17c1c95f46dc3afd0a551707b82c2339c038d45327fdc99a3977d0b" alt="" style=""></p><h2>Resources</h2><p><strong>Read or watch</strong>:</p><ul><li><a href="/rltoken/uSJcrn4-wamVCfbQQtI9EA" title="An introduction to Reinforcement Learning" target="_blank">An introduction to Reinforcement Learning</a></li><li><a href="/rltoken/OZSdqt0W5xx76Oigx3TzQg" title="Simple Reinforcement Learning: Q-learning" target="_blank">Simple Reinforcement Learning: Q-learning</a></li><li><a href="/rltoken/km2Nyp6zyAast1k5v9P_wQ" title="Markov Decision Processes (MDPs) - Structuring a Reinforcement Learning Problem" target="_blank">Markov Decision Processes (MDPs) - Structuring a Reinforcement Learning Problem</a></li><li><a href="/rltoken/mM6iGVu8uSr7siZJCM-D-Q" title="Expected Return - What Drives a Reinforcement Learning Agent in an MDP" target="_blank">Expected Return - What Drives a Reinforcement Learning Agent in an MDP</a></li><li><a href="/rltoken/HgOMxHB7SipUwDk6s3ZhUA" title="Policies and Value Functions - Good Actions for a Reinforcement Learning Agent" target="_blank">Policies and Value Functions - Good Actions for a Reinforcement Learning Agent</a></li><li><a href="/rltoken/Pd4kGKXr9Pd0qQ4RO93Xww" title="What do Reinforcement Learning Algorithms Learn - Optimal Policies" target="_blank">What do Reinforcement Learning Algorithms Learn - Optimal Policies</a></li><li><a href="/rltoken/vj2E0Jizi5qUKn6hLUnVSQ" title="Q-Learning Explained - A Reinforcement Learning Technique" target="_blank">Q-Learning Explained - A Reinforcement Learning Technique</a></li><li><a href="/rltoken/zQNxN36--R7hzP0ktiKOsg" title="Exploration vs. Exploitation - Learning the Optimal Reinforcement Learning Policy" target="_blank">Exploration vs. Exploitation - Learning the Optimal Reinforcement Learning Policy</a></li><li><a href="/rltoken/GMcf0lCJ-SlaF6FSUKaozA" title="OpenAI Gym and Python for Q-learning - Reinforcement Learning Code Project" target="_blank">OpenAI Gym and Python for Q-learning - Reinforcement Learning Code Project</a></li><li><a href="/rltoken/GE2nKBHgehHdd_XN7lK0Gw" title="Train Q-learning Agent with Python - Reinforcement Learning Code Project" target="_blank">Train Q-learning Agent with Python - Reinforcement Learning Code Project</a></li><li><a href="/rltoken/Dz37ih49PpmrJicq_IP3aA" title="Markov Decision Processes" target="_blank">Markov Decision Processes</a></li></ul><p><strong>Definitions to skim:</strong></p><ul><li><a href="/rltoken/z1eKcn91HbmHYtdwYEEXOQ" title="Reinforcement Learning" target="_blank">Reinforcement Learning</a></li><li><a href="/rltoken/PCdKyrHQRNARmxeSUCiOYQ" title="Markov Decision Process" target="_blank">Markov Decision Process</a></li><li><a href="/rltoken/T80msozXZ3wlSmq0ScCvrQ" title="Q-learning" target="_blank">Q-learning</a></li></ul><p><strong>References</strong>:</p><ul><li><a href="/rltoken/P8gDRc_PRTeK4okeztvmDQ" title="OpenAI Gym" target="_blank">OpenAI Gym</a></li><li><a href="https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py" title="OpenAI Gym: Frozen Lake env" target="_blank">OpenAI Gym: Frozen Lake env</a></li></ul><h2>Learning Objectives</h2><ul><li>What is a Markov Decision Process?</li><li>What is an environment?</li><li>What is an agent?</li><li>What is a state?</li><li>What is a policy function?</li><li>What is a value function? a state-value function? an action-value function?</li><li>What is a discount factor?</li><li>What is the Bellman equation?</li><li>What is epsilon greedy?</li><li>What is Q-learning?</li></ul><h2>Requirements</h2><h3>General</h3><ul><li>Allowed editors: <code>vi</code>, <code>vim</code>, <code>emacs</code></li><li>All your files will be interpreted/compiled on Ubuntu 16.04 LTS using <code>python3</code> (version 3.5)</li><li>Your files will be executed with <code>numpy</code> (version 1.15), and <code>gym</code> (version 0.7)</li><li>All your files should end with a new line</li><li>The first line of all your files should be exactly <code>#!/usr/bin/env python3</code></li><li>A <code>README.md</code> file, at the root of the folder of the project, is mandatory</li><li>Your code should use the <code>pycodestyle</code> style (version 2.4)</li><li>All your modules should have documentation (<code>python3 -c 'print(__import__("my_module").__doc__)'</code>)</li><li>All your classes should have documentation (<code>python3 -c 'print(__import__("my_module").MyClass.__doc__)'</code>)</li><li>All your functions (inside and outside a class) should have documentation (<code>python3 -c 'print(__import__("my_module").my_function.__doc__)'</code> and <code>python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'</code>)</li><li>All your files must be executable</li><li><strong>Your code should use the minimum number of operations</strong></li></ul><h2>Installing OpenAI’s Gym</h2><precode language="" precodenum="0"></precode></article><hr class="gap"><h2 class="gap">Quiz questions</h2><p id="quiz_questions_collapse_toggle">Show</p><section class="formatted-content quiz_questions_show_container" style="display: none;"><div class="quiz_question_item_container" data-role="quiz_question1549" data-position="1"><div class=" clearfix" id="quiz_question-1549"><h4 class="quiz_question">Question #0</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is reinforcement learning?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1549"><li class=""><input type="checkbox" data-quiz-question-id="1549" data-quiz-answer-id="1597064459175" disabled=""><p>A type of supervised learning, because the rewards supervise the learning</p></li><li class=""><input type="checkbox" data-quiz-question-id="1549" data-quiz-answer-id="1597064470601" disabled=""><p>A type of unsupervised learning, because there are no labels for each action</p></li><li class=""><input type="checkbox" data-quiz-question-id="1549" data-quiz-answer-id="1597064530798" disabled="" checked=""><p>Its own subcategory of machine learning</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1550" data-position="2"><div class=" clearfix" id="quiz_question-1550"><h4 class="quiz_question">Question #1</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is an environment?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1550"><li class=""><input type="checkbox" data-quiz-question-id="1550" data-quiz-answer-id="1597064553450" disabled="" checked=""><p>The place in which actions can be performed</p></li><li class=""><input type="checkbox" data-quiz-question-id="1550" data-quiz-answer-id="1597064595587" disabled=""><p>A description of what the agent sees</p></li><li class=""><input type="checkbox" data-quiz-question-id="1550" data-quiz-answer-id="1597064613427" disabled=""><p>A list of actions that can be performed</p></li><li class=""><input type="checkbox" data-quiz-question-id="1550" data-quiz-answer-id="1597064684101" disabled=""><p>A description of which actions the agent should perform</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1551" data-position="3"><div class=" clearfix" id="quiz_question-1551"><h4 class="quiz_question">Question #2</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>An agent chooses its action based on:</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1551"><li class=""><input type="checkbox" data-quiz-question-id="1551" data-quiz-answer-id="1597064723091" disabled="" checked=""><p>The current state</p></li><li class=""><input type="checkbox" data-quiz-question-id="1551" data-quiz-answer-id="1597064777168" disabled="" checked=""><p>The value function</p></li><li class=""><input type="checkbox" data-quiz-question-id="1551" data-quiz-answer-id="1597064804098" disabled="" checked=""><p>The policy function</p></li><li class=""><input type="checkbox" data-quiz-question-id="1551" data-quiz-answer-id="1597064811945" disabled="" checked=""><p>The previous reward</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1553" data-position="4"><div class=" clearfix" id="quiz_question-1553"><h4 class="quiz_question">Question #3</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is a policy function?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1553"><li class=""><input type="checkbox" data-quiz-question-id="1553" data-quiz-answer-id="1597064872304" disabled=""><p>A description of how the agent should be rewarded</p></li><li class=""><input type="checkbox" data-quiz-question-id="1553" data-quiz-answer-id="1597064897527" disabled="" checked=""><p>A description of how the agent should behave</p></li><li class=""><input type="checkbox" data-quiz-question-id="1553" data-quiz-answer-id="1597064922926" disabled=""><p>A description of how the agent could be rewarded in the future</p></li><li class=""><input type="checkbox" data-quiz-question-id="1553" data-quiz-answer-id="1597064941601" disabled="" checked=""><p>A function that is learned</p></li><li class=""><input type="checkbox" data-quiz-question-id="1553" data-quiz-answer-id="1597064983883" disabled=""><p>A function that is set at the beginning</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1554" data-position="5"><div class=" clearfix" id="quiz_question-1554"><h4 class="quiz_question">Question #4</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is a value function?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1554"><li class=""><input type="checkbox" data-quiz-question-id="1554" data-quiz-answer-id="1597064976871" disabled=""><p>A description of how the agent should be rewarded</p></li><li class=""><input type="checkbox" data-quiz-question-id="1554" data-quiz-answer-id="1597065040069" disabled=""><p>A description of how the agent should behave</p></li><li class=""><input type="checkbox" data-quiz-question-id="1554" data-quiz-answer-id="1597065041922" disabled="" checked=""><p>A description of how the agent could be rewarded in the future</p></li><li class=""><input type="checkbox" data-quiz-question-id="1554" data-quiz-answer-id="1597065043314" disabled="" checked=""><p>A function that is learned</p></li><li class=""><input type="checkbox" data-quiz-question-id="1554" data-quiz-answer-id="1597065044824" disabled=""><p>A function that is set at the beginning</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1555" data-position="6"><div class=" clearfix" id="quiz_question-1555"><h4 class="quiz_question">Question #5</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is epsilon-greedy?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1555"><li class=""><input type="checkbox" data-quiz-question-id="1555" data-quiz-answer-id="1597065092154" disabled=""><p>A type of policy function</p></li><li class=""><input type="checkbox" data-quiz-question-id="1555" data-quiz-answer-id="1597065108393" disabled=""><p>A type of value function</p></li><li class=""><input type="checkbox" data-quiz-question-id="1555" data-quiz-answer-id="1597065116708" disabled=""><p>A way to balance policy and value functions</p></li><li class=""><input type="checkbox" data-quiz-question-id="1555" data-quiz-answer-id="1597065133195" disabled="" checked=""><p>A balance exploration and exploitation</p></li></ul><!-- Quiz question Tips --></div></div><div class="quiz_question_item_container" data-role="quiz_question1556" data-position="7"><div class=" clearfix" id="quiz_question-1556"><h4 class="quiz_question">Question #6</h4><!-- Quiz question tags --><!-- Quiz question Body --><p>What is Q-learning?</p><!-- Quiz question Answers --><ul class="quiz_question_answers" data-question-id="1556"><li class=""><input type="checkbox" data-quiz-question-id="1556" data-quiz-answer-id="1597065211073" disabled="" checked=""><p>A reinforcement learning algorithm</p></li><li class=""><input type="checkbox" data-quiz-question-id="1556" data-quiz-answer-id="1597065222265" disabled=""><p>A deep reinforcement learning algorithm</p></li><li class=""><input type="checkbox" data-quiz-question-id="1556" data-quiz-answer-id="1597065232361" disabled="" checked=""><p>A value-based learning algorithm</p></li><li class=""><input type="checkbox" data-quiz-question-id="1556" data-quiz-answer-id="1597065318628" disabled=""><p>A policy-based learning algorithm</p></li><li class=""><input type="checkbox" data-quiz-question-id="1556" data-quiz-answer-id="1597065330302" disabled=""><p>A model-based approach</p></li></ul><!-- Quiz question Tips --></div></div></section><!-- Servers --><!-- Tasks --><hr class="gap"><h2 class="gap">Tasks</h2><section class="formatted-content"><div data-role="task6249" data-position="1"><div class=" clearfix gap" id="task-6249"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="6249"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="6249" data-project-id="783" data-toggle="modal" data-target="#task-6249-users-done-modal"> Help </button></div><h4 class="task"> 0. Load the Environment <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def load_frozen_lake(desc=None, map_name=None, is_slippery=False):</code> that loads the pre-made <code>FrozenLakeEnv</code> evnironment from OpenAI’s <code>gym</code>:</p><ul><li><code>desc</code> is either <code>None</code> or a list of lists containing a custom description of the map to load for the environment</li><li><code>map_name</code> is either <code>None</code> or a string containing the pre-made map to load</li><li><em>Note: If both <code>desc</code> and <code>map_name</code> are <code>None</code>, the environment will load a randomly generated 8x8 map</em></li><li><code>is_slippery</code> is a boolean to determine if the ice is slippery</li><li>Returns: the environment</li></ul><precode language="" precodenum="1"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>reinforcement_learning/0x00-q_learning</code></li><li>File: <code>0-load_env.py</code></li></ul></div></div><div data-role="task6250" data-position="2"><div class=" clearfix gap" id="task-6250"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="6250"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="6250" data-project-id="783" data-toggle="modal" data-target="#task-6250-users-done-modal"> Help </button></div><h4 class="task"> 1. Initialize Q-table <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def q_init(env):</code> that initializes the Q-table:</p><ul><li><code>env</code> is the <code>FrozenLakeEnv</code> instance</li><li>Returns: the Q-table as a <code>numpy.ndarray</code> of zeros</li></ul><precode language="" precodenum="2"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>reinforcement_learning/0x00-q_learning</code></li><li>File: <code>1-q_init.py</code></li></ul></div></div><div data-role="task6251" data-position="3"><div class=" clearfix gap" id="task-6251"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="6251"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="6251" data-project-id="783" data-toggle="modal" data-target="#task-6251-users-done-modal"> Help </button></div><h4 class="task"> 2. Epsilon Greedy <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def epsilon_greedy(Q, state, epsilon):</code> that uses epsilon-greedy to determine the next action:</p><ul><li><code>Q</code> is a <code>numpy.ndarray</code> containing the q-table</li><li><code>state</code> is the current state</li><li><code>epsilon</code> is the epsilon to use for the calculation</li><li>You should sample <code>p</code> with <code>numpy.random.uniformn</code> to determine if your algorithm should explore or exploit</li><li>If exploring, you should pick the next action with <code>numpy.random.randint</code> from all possible actions</li><li>Returns: the next action index</li></ul><precode language="" precodenum="3"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>reinforcement_learning/0x00-q_learning</code></li><li>File: <code>2-epsilon_greedy.py</code></li></ul></div></div><div data-role="task6252" data-position="4"><div class=" clearfix gap" id="task-6252"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="6252"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="6252" data-project-id="783" data-toggle="modal" data-target="#task-6252-users-done-modal"> Help </button></div><h4 class="task"> 3. Q-learning <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write the function <code>def train(env, Q, episodes=5000, max_steps=100, alpha=0.1, gamma=0.99, epsilon=1, min_epsilon=0.1, epsilon_decay=0.05):</code> that performs Q-learning:</p><ul><li><code>env</code> is the <code>FrozenLakeEnv</code> instance</li><li><code>Q</code> is a <code>numpy.ndarray</code> containing the Q-table</li><li><code>episodes</code> is the total number of episodes to train over</li><li><code>max_steps</code> is the maximum number of steps per episode</li><li><code>alpha</code> is the learning rate</li><li><code>gamma</code> is the discount rate</li><li><code>epsilon</code> is the initial threshold for epsilon greedy</li><li><code>min_epsilon</code> is the minimum value that <code>epsilon</code> should decay to</li><li><code>epsilon_decay</code> is the decay rate for updating <code>epsilon</code> between episodes</li><li>When the agent falls in a hole, the reward should be updated to be <code>-1</code></li><li>Returns: <code>Q, total_rewards</code><ul><li><code>Q</code> is the updated Q-table</li><li><code>total_rewards</code> is a list containing the rewards per episode</li></ul></li></ul><precode language="" precodenum="4"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>reinforcement_learning/0x00-q_learning</code></li><li>File: <code>3-q_learning.py</code></li></ul></div></div><div data-role="task6253" data-position="5"><div class=" clearfix gap" id="task-6253"><span id="user_id" data-id="870"></span><div class="student_task_controls"><!-- button Done --><button class="student_task_done btn btn-default no" data-task-id="6253"><span class="no"><i class="fa fa-square-o"></i></span><span class="yes"><i class="fa fa-check-square-o"></i></span><span class="pending"><i class="fa fa-spinner fa-pulse"></i></span> Done<span class="no pending">?</span><span class="yes">!</span></button><br><!-- button Help! --><button class="users_done_for_task btn btn-default btn-default" data-task-id="6253" data-project-id="783" data-toggle="modal" data-target="#task-6253-users-done-modal"> Help </button></div><h4 class="task"> 4. Play <span class="alert alert-warning mandatory-optional"> mandatory </span></h4><!-- Progress vs Score --><!-- Task Body --><p>Write a function <code>def play(env, Q, max_steps=100):</code> that has the trained agent play an episode:</p><ul><li><code>env</code> is the <code>FrozenLakeEnv</code> instance</li><li><code>Q</code> is a <code>numpy.ndarray</code> containing the Q-table</li><li><code>max_steps</code> is the maximum number of steps in the episode</li><li>Each state of the board should be displayed via the console</li><li>You should always exploit the Q-table</li><li>Returns: the total rewards for the episode</li></ul><precode language="" precodenum="5"></precode><!-- Task URLs --><!-- Github information --><p class="sm-gap"><strong>Repo:</strong></p><ul><li>GitHub repository: <code>holbertonschool-machine_learning</code></li><li>Directory: <code>reinforcement_learning/0x00-q_learning</code></li><li>File: <code>4-play.py</code></li></ul></div></div></section></article>
